<!DOCTYPE html>
<html>
<head>
  <meta name="databricks-html-version" content="1">
<title>jlitven@gmail.com / spark_ML - Databricks</title>

<meta charset="utf-8">
<meta name="google" content="notranslate">
<meta http-equiv="Content-Language" content="en">
<meta http-equiv="Content-Type" content="text/html; charset=UTF8">
<link rel="stylesheet"
  href="https://fonts.googleapis.com/css?family=Source+Code+Pro:400,700">

<link rel="stylesheet" type="text/css" href="https://databricks-prod-cloudfront.cloud.databricks.com/static/e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855/lib/css/bootstrap.min.css">
<link rel="stylesheet" type="text/css" href="https://databricks-prod-cloudfront.cloud.databricks.com/static/e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855/lib/jquery-ui-bundle/jquery-ui.min.css">
<link rel="stylesheet" type="text/css" href="https://databricks-prod-cloudfront.cloud.databricks.com/static/e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855/css/main.css">
<link rel="stylesheet" href="https://databricks-prod-cloudfront.cloud.databricks.com/static/e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855/css/print.css" media="print">
<link rel="icon" type="image/png" href="https://databricks-prod-cloudfront.cloud.databricks.com/static/e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855/img/favicon.ico"/>
<script>window.settings = {"enableSshKeyUI":true,"enableAutoCompleteAsYouType":[],"devTierName":"Community Edition","workspaceFeaturedLinks":[{"linkURI":"https://docs.databricks.com/index.html","displayName":"Documentation","icon":"question"},{"linkURI":"https://docs.databricks.com/release-notes/product/latest.html","displayName":"Release Notes","icon":"code"},{"linkURI":"https://docs.databricks.com/spark/latest/training/index.html","displayName":"Training & Tutorials","icon":"graduation-cap"}],"enableClearStateFeature":false,"dbcForumURL":"http://forums.databricks.com/","maxCustomTags":45,"enableInstanceProfilesUIInJobs":true,"nodeInfo":{"node_types":[{"spark_heap_memory":21145,"instance_type_id":"r3.xlarge","node_type_id":"r3.xlarge","description":"r3.xlarge (beta)","support_cluster_tags":true,"container_memory_mb":26432,"memory_mb":31232,"category":"Memory Optimized","num_cores":4.0,"support_ebs_volumes":true},{"spark_heap_memory":46131,"instance_type_id":"r3.2xlarge","node_type_id":"r3.2xlarge","description":"r3.2xlarge (beta)","support_cluster_tags":true,"container_memory_mb":57664,"memory_mb":62464,"category":"Memory Optimized","num_cores":8.0,"support_ebs_volumes":true},{"spark_heap_memory":96102,"instance_type_id":"r3.4xlarge","node_type_id":"r3.4xlarge","description":"r3.4xlarge (beta)","support_cluster_tags":true,"container_memory_mb":120128,"memory_mb":124928,"category":"Memory Optimized","num_cores":16.0,"support_ebs_volumes":true},{"spark_heap_memory":196044,"instance_type_id":"r3.8xlarge","node_type_id":"r3.8xlarge","description":"r3.8xlarge (beta)","support_cluster_tags":true,"container_memory_mb":245056,"memory_mb":249856,"category":"Memory Optimized","num_cores":32.0,"support_ebs_volumes":true},{"spark_heap_memory":8448,"instance_type_id":"c3.2xlarge","node_type_id":"c3.2xlarge","description":"c3.2xlarge (beta)","support_cluster_tags":true,"container_memory_mb":10560,"memory_mb":15360,"category":"Compute Optimized","num_cores":8.0,"support_ebs_volumes":true},{"spark_heap_memory":20736,"instance_type_id":"c3.4xlarge","node_type_id":"c3.4xlarge","description":"c3.4xlarge (beta)","support_cluster_tags":true,"container_memory_mb":25920,"memory_mb":30720,"category":"Compute Optimized","num_cores":16.0,"support_ebs_volumes":true},{"spark_heap_memory":45312,"instance_type_id":"c3.8xlarge","node_type_id":"c3.8xlarge","description":"c3.8xlarge (beta)","support_cluster_tags":true,"container_memory_mb":56640,"memory_mb":61440,"category":"Compute Optimized","num_cores":32.0,"support_ebs_volumes":true},{"spark_heap_memory":21145,"instance_type_id":"i2.xlarge","node_type_id":"i2.xlarge","description":"i2.xlarge (beta)","support_cluster_tags":true,"container_memory_mb":26432,"memory_mb":31232,"category":"Storage Optimized","num_cores":4.0,"support_ebs_volumes":true},{"spark_heap_memory":46131,"instance_type_id":"i2.2xlarge","node_type_id":"i2.2xlarge","description":"i2.2xlarge (beta)","support_cluster_tags":true,"container_memory_mb":57664,"memory_mb":62464,"category":"Storage Optimized","num_cores":8.0,"support_ebs_volumes":true},{"spark_heap_memory":96102,"instance_type_id":"i2.4xlarge","node_type_id":"i2.4xlarge","description":"i2.4xlarge (beta)","support_cluster_tags":true,"container_memory_mb":120128,"memory_mb":124928,"category":"Storage Optimized","num_cores":16.0,"support_ebs_volumes":true},{"spark_heap_memory":196044,"instance_type_id":"i2.8xlarge","node_type_id":"i2.8xlarge","description":"i2.8xlarge (beta)","support_cluster_tags":true,"container_memory_mb":245056,"memory_mb":249856,"category":"Storage Optimized","num_cores":32.0,"support_ebs_volumes":true},{"spark_heap_memory":23800,"instance_type_id":"r3.2xlarge","node_type_id":"memory-optimized","description":"Memory Optimized","support_cluster_tags":false,"container_memory_mb":28000,"memory_mb":30720,"category":"Memory Optimized","num_cores":4.0,"support_ebs_volumes":false},{"spark_heap_memory":9702,"instance_type_id":"c3.4xlarge","node_type_id":"compute-optimized","description":"Compute Optimized","support_cluster_tags":false,"container_memory_mb":12128,"memory_mb":15360,"category":"Compute Optimized","num_cores":8.0,"support_ebs_volumes":false}],"default_node_type_id":"memory-optimized"},"enableThirdPartyApplicationsUI":false,"enableClusterAcls":true,"notebookRevisionVisibilityHorizon":0,"enableTableHandler":true,"maxEbsVolumesPerInstance":10,"isAdmin":true,"deltaProcessingBatchSize":1000,"enableLargeResultDownload":true,"zoneInfos":[{"id":"us-east-1e","isDefault":true},{"id":"us-east-1b","isDefault":false},{"id":"us-east-1c","isDefault":false},{"id":"us-east-1d","isDefault":false}],"enableEBSVolumesUIForJobs":true,"enablePublishNotebooks":false,"enableMaxConcurrentRuns":false,"enableJobAclsConfig":true,"enableFullTextSearch":true,"enableElasticSparkUI":true,"enableNewClustersCreate":false,"clusters":true,"allowRunOnPendingClusters":true,"applications":false,"fileStoreBase":"FileStore","enableSshKeyUIInJobs":true,"enableDetachAndAttachSubMenu":false,"configurableSparkOptionsSpec":[{"keyPattern":"spark\\.kryo(\\.[^\\.]+)+","valuePattern":".*","keyPatternDisplay":"spark.kryo.*","valuePatternDisplay":"*","description":"Configuration options for Kryo serialization"},{"keyPattern":"spark\\.io\\.compression\\.codec","valuePattern":"(lzf|snappy|org\\.apache\\.spark\\.io\\.LZFCompressionCodec|org\\.apache\\.spark\\.io\\.SnappyCompressionCodec)","keyPatternDisplay":"spark.io.compression.codec","valuePatternDisplay":"snappy|lzf","description":"The codec used to compress internal data such as RDD partitions, broadcast variables and shuffle outputs."},{"keyPattern":"spark\\.serializer","valuePattern":"(org\\.apache\\.spark\\.serializer\\.JavaSerializer|org\\.apache\\.spark\\.serializer\\.KryoSerializer)","keyPatternDisplay":"spark.serializer","valuePatternDisplay":"org.apache.spark.serializer.JavaSerializer|org.apache.spark.serializer.KryoSerializer","description":"Class to use for serializing objects that will be sent over the network or need to be cached in serialized form."},{"keyPattern":"spark\\.rdd\\.compress","valuePattern":"(true|false)","keyPatternDisplay":"spark.rdd.compress","valuePatternDisplay":"true|false","description":"Whether to compress serialized RDD partitions (e.g. for StorageLevel.MEMORY_ONLY_SER). Can save substantial space at the cost of some extra CPU time."},{"keyPattern":"spark\\.speculation","valuePattern":"(true|false)","keyPatternDisplay":"spark.speculation","valuePatternDisplay":"true|false","description":"Whether to use speculation (recommended off for streaming)"},{"keyPattern":"spark\\.es(\\.[^\\.]+)+","valuePattern":".*","keyPatternDisplay":"spark.es.*","valuePatternDisplay":"*","description":"Configuration options for ElasticSearch"},{"keyPattern":"es(\\.([^\\.]+))+","valuePattern":".*","keyPatternDisplay":"es.*","valuePatternDisplay":"*","description":"Configuration options for ElasticSearch"},{"keyPattern":"spark\\.(storage|shuffle)\\.memoryFraction","valuePattern":"0?\\.0*([1-9])([0-9])*","keyPatternDisplay":"spark.(storage|shuffle).memoryFraction","valuePatternDisplay":"(0.0,1.0)","description":"Fraction of Java heap to use for Spark's shuffle or storage"},{"keyPattern":"spark\\.streaming\\.backpressure\\.enabled","valuePattern":"(true|false)","keyPatternDisplay":"spark.streaming.backpressure.enabled","valuePatternDisplay":"true|false","description":"Enables or disables Spark Streaming's internal backpressure mechanism (since 1.5). This enables the Spark Streaming to control the receiving rate based on the current batch scheduling delays and processing times so that the system receives only as fast as the system can process. Internally, this dynamically sets the maximum receiving rate of receivers. This rate is upper bounded by the values `spark.streaming.receiver.maxRate` and `spark.streaming.kafka.maxRatePerPartition` if they are set."},{"keyPattern":"spark\\.streaming\\.receiver\\.maxRate","valuePattern":"^([0-9]{1,})$","keyPatternDisplay":"spark.streaming.receiver.maxRate","valuePatternDisplay":"numeric","description":"Maximum rate (number of records per second) at which each receiver will receive data. Effectively, each stream will consume at most this number of records per second. Setting this configuration to 0 or a negative number will put no limit on the rate. See the deployment guide in the Spark Streaming programing guide for mode details."},{"keyPattern":"spark\\.streaming\\.kafka\\.maxRatePerPartition","valuePattern":"^([0-9]{1,})$","keyPatternDisplay":"spark.streaming.kafka.maxRatePerPartition","valuePatternDisplay":"numeric","description":"Maximum rate (number of records per second) at which data will be read from each Kafka partition when using the Kafka direct stream API introduced in Spark 1.3. See the Kafka Integration guide for more details."},{"keyPattern":"spark\\.streaming\\.kafka\\.maxRetries","valuePattern":"^([0-9]{1,})$","keyPatternDisplay":"spark.streaming.kafka.maxRetries","valuePatternDisplay":"numeric","description":"Maximum number of consecutive retries the driver will make in order to find the latest offsets on the leader of each partition (a default value of 1 means that the driver will make a maximum of 2 attempts). Only applies to the Kafka direct stream API introduced in Spark 1.3."},{"keyPattern":"spark\\.streaming\\.ui\\.retainedBatches","valuePattern":"^([0-9]{1,})$","keyPatternDisplay":"spark.streaming.ui.retainedBatches","valuePatternDisplay":"numeric","description":"How many batches the Spark Streaming UI and status APIs remember before garbage collecting."}],"enableReactNotebookComments":true,"enableAdminPasswordReset":true,"enableResetPassword":true,"maxClusterTagValueLength":255,"enableJobsSparkUpgrade":true,"sparkVersions":[{"key":"1.6.x-ubuntu15.10","displayName":"Spark 1.6.x (Hadoop 1)","packageLabel":"spark-image-8cea23fb9094e174bf5815d79009f4a8e383eb86cf2909cf6c6434ed8da2a16a","upgradable":true,"deprecated":false,"customerVisible":false},{"key":"1.4.x-ubuntu15.10","displayName":"Spark 1.4.1 (Hadoop 1)","packageLabel":"spark-image-f710650fb8aaade8e4e812368ea87c45cd8cd0b5e6894ca6c94f3354e8daa6dc","upgradable":true,"deprecated":false,"customerVisible":true},{"key":"2.0.0-ubuntu15.10-scala2.10","displayName":"Spark 2.0.0 (Scala 2.10)","packageLabel":"spark-image-073c1b52ace74f251fae2680624a0d8d184a8b57096d1c21c5ce56c29be6a37a","upgradable":true,"deprecated":false,"customerVisible":true},{"key":"2.1.0-db1-scala2.11","displayName":"Spark 2.1.0 RC5 (Scala 2.11)","packageLabel":"spark-image-20833506f690f3a49c53fb08837cb9b98f7f2e15380f1fb26efc158d953e94c8","upgradable":true,"deprecated":false,"customerVisible":true},{"key":"1.6.x-ubuntu15.10-hadoop1","displayName":"Spark 1.6.x (Hadoop 1)","packageLabel":"spark-image-8cea23fb9094e174bf5815d79009f4a8e383eb86cf2909cf6c6434ed8da2a16a","upgradable":true,"deprecated":false,"customerVisible":false},{"key":"1.6.1-ubuntu15.10-hadoop1","displayName":"Spark 1.6.1 (Hadoop 1)","packageLabel":"spark-image-21d1cac181b7b8856dd1b4214a3a734f95b5289089349db9d9c926cb87d843db","upgradable":true,"deprecated":false,"customerVisible":true},{"key":"2.0.x-gpu-scala2.11","displayName":"Spark 2.0 (Auto-updating, GPU, Scala 2.11 experimental)","packageLabel":"spark-image-6c2dd678fff350c03ba0e945bab52d0080cd857a39c99a22131b3e824bb8096f","upgradable":true,"deprecated":false,"customerVisible":true},{"key":"1.6.2-ubuntu15.10-hadoop1","displayName":"Spark 1.6.2 (Hadoop 1)","packageLabel":"spark-image-8cea23fb9094e174bf5815d79009f4a8e383eb86cf2909cf6c6434ed8da2a16a","upgradable":true,"deprecated":false,"customerVisible":true},{"key":"1.6.3-db1-hadoop2-scala2.10","displayName":"Spark 1.6.3-db1 (Hadoop 2, Scala 2.10)","packageLabel":"spark-image-eaa8d9b990015a14e032fb2e2e15be0b8d5af9627cd01d855df728b67969d5d9","upgradable":true,"deprecated":false,"customerVisible":true},{"key":"1.6.2-ubuntu15.10-hadoop2","displayName":"Spark 1.6.2 (Hadoop 2)","packageLabel":"spark-image-161245e66d887cd775e23286a54bab0b146143e1289f25bd1732beac454a1561","upgradable":true,"deprecated":false,"customerVisible":true},{"key":"1.6.1-ubuntu15.10-hadoop2","displayName":"Spark 1.6.1 (Hadoop 2)","packageLabel":"spark-image-4cafdf8bc6cba8edad12f441e3b3f0a8ea27da35c896bc8290e16b41fd15496a","upgradable":true,"deprecated":false,"customerVisible":true},{"key":"2.0.2-db2-scala2.10","displayName":"Spark 2.0.2-db2 (Scala 2.10)","packageLabel":"spark-image-36d48f22cca7a907538e07df71847dd22aaf84a852c2eeea2dcefe24c681602f","upgradable":true,"deprecated":false,"customerVisible":true},{"key":"2.0.x-ubuntu15.10-scala2.11","displayName":"Spark 2.0 (Ubuntu 15.10, Scala 2.11, deprecated)","packageLabel":"spark-image-8e1c50d626a52eac5a6c8129e09ae206ba9890f4523775f77af4ad6d99a64c44","upgradable":true,"deprecated":true,"customerVisible":true},{"key":"2.0.x-scala2.10","displayName":"Spark 2.0 (Auto-updating, Scala 2.10)","packageLabel":"spark-image-4f22a8d3016bc3dce9e839b10418815a7d28afff3a027b43bd2b041c42b2a89d","upgradable":true,"deprecated":false,"customerVisible":true},{"key":"2.0.2-db1-scala2.11","displayName":"Spark 2.0.2-db1 (Scala 2.11)","packageLabel":"spark-image-c2d623f03dd44097493c01aa54a941fc31978ebe6d759b36c75b716b2ff6ab9c","upgradable":true,"deprecated":false,"customerVisible":true},{"key":"1.5.x-ubuntu15.10","displayName":"Spark 1.5.2 (Hadoop 1)","packageLabel":"spark-image-c9d2a8abf41f157a4acc6d52bc721090346f6fea2de356f3a66e388f54481698","upgradable":true,"deprecated":false,"customerVisible":true},{"key":"2.0.x-scala2.11","displayName":"Spark 2.0 (Auto-updating, Scala 2.11)","packageLabel":"spark-image-596490ba3e0ca4b62abb048923fc70de84e319cf527bb7a5a8f609bbf780bed8","upgradable":true,"deprecated":false,"customerVisible":true},{"key":"2.0.2-db2-scala2.11","displayName":"Spark 2.0.2-db2 (Scala 2.11)","packageLabel":"spark-image-4fa852ba378e97815083b96c9cada7b962a513ec23554a5fc849f7f1dd8c065a","upgradable":true,"deprecated":false,"customerVisible":true},{"key":"1.3.x-ubuntu15.10","displayName":"Spark 1.3.0 (Hadoop 1)","packageLabel":"spark-image-40d2842670bc3dc178b14042501847d76171437ccf70613fa397a7a24c48b912","upgradable":true,"deprecated":false,"customerVisible":true},{"key":"2.0.1-db1-scala2.11","displayName":"Spark 2.0.1-db1 (Scala 2.11)","packageLabel":"spark-image-10ab19f634bbfdb860446c326a9f76dc25bfa87de6403b980566279142a289ea","upgradable":true,"deprecated":false,"customerVisible":true},{"key":"1.6.3-db1-hadoop1-scala2.10","displayName":"Spark 1.6.3-db1 (Hadoop 1, Scala 2.10)","packageLabel":"spark-image-d50af1032799546b8ccbeeb76889a20c819ebc2a0e68ea20920cb30d3895d3ae","upgradable":true,"deprecated":false,"customerVisible":true},{"key":"2.0.2-db1-scala2.10","displayName":"Spark 2.0.2-db1 (Scala 2.10)","packageLabel":"spark-image-654bdd6e9bad70079491987d853b4b7abf3b736fff099701501acaabe0e75c41","upgradable":true,"deprecated":false,"customerVisible":true},{"key":"2.0.x-ubuntu15.10","displayName":"Spark 2.0 (Ubuntu 15.10, Scala 2.10, deprecated)","packageLabel":"spark-image-a659f3909d51b38d297b20532fc807ecf708cfb7440ce9b090c406ab0c1e4b7e","upgradable":true,"deprecated":true,"customerVisible":true},{"key":"2.0.1-db1-scala2.10","displayName":"Spark 2.0.1-db1 (Scala 2.10)","packageLabel":"spark-image-5a13c2db3091986a4e7363006cc185c5b1108c7761ef5d0218506cf2e6643840","upgradable":true,"deprecated":false,"customerVisible":true},{"key":"2.1.0-db1-scala2.10","displayName":"Spark 2.1.0 RC5 (Scala 2.10)","packageLabel":"spark-image-f430b652793cbc27e454dc629737ae2bc04b75a1fecd68a5d90c44eca7543756","upgradable":true,"deprecated":false,"customerVisible":true},{"key":"1.6.0-ubuntu15.10","displayName":"Spark 1.6.0 (Hadoop 1)","packageLabel":"spark-image-10ef758029b8c7e19cd7f4fb52fff9180d75db92ca071bd94c47f3c1171a7cb5","upgradable":true,"deprecated":false,"customerVisible":true},{"key":"1.6.x-ubuntu15.10-hadoop2","displayName":"Spark 1.6.x (Hadoop 2)","packageLabel":"spark-image-161245e66d887cd775e23286a54bab0b146143e1289f25bd1732beac454a1561","upgradable":true,"deprecated":false,"customerVisible":false},{"key":"2.0.0-ubuntu15.10-scala2.11","displayName":"Spark 2.0.0 (Scala 2.11)","packageLabel":"spark-image-b4ec141e751f201399f8358a82efee202560f7ed05e1a04a2ae8778f6324b909","upgradable":true,"deprecated":false,"customerVisible":true}],"enableRestrictedClusterCreation":false,"enableFeedback":true,"enableClusterAutoScaling":true,"enableUserVisibleDefaultTags":false,"defaultNumWorkers":8,"serverContinuationTimeoutMillis":10000,"driverStderrFilePrefix":"stderr","enableNotebookRefresh":true,"accountsOwnerUrl":"https://accounts.cloud.databricks.com/registration.html#login","driverStdoutFilePrefix":"stdout","defaultNodeTypeToPricingUnitsMap":{"r3.2xlarge":2,"class-node":1,"p2.8xlarge":16,"r3.8xlarge":8,"dev-tier-node":1,"c3.8xlarge":4,"r3.4xlarge":4,"i2.4xlarge":6,"development-node":1,"i2.2xlarge":3,"g2.8xlarge":6,"memory-optimized":1,"p2.16xlarge":24,"c3.2xlarge":1,"c4.2xlarge":1,"i2.xlarge":1.5,"compute-optimized":1,"c4.4xlarge":2,"c3.4xlarge":2,"g2.2xlarge":1.5,"p2.xlarge":2,"c4.8xlarge":4,"r3.xlarge":1,"i2.8xlarge":12},"enableSparkDocsSearch":true,"sparkHistoryServerEnabled":true,"enableEBSVolumesUI":true,"sanitizeMarkdownHtml":true,"enableIPythonImportExport":true,"enableClusterTagsUIForJobs":false,"enableClusterTagsUI":false,"enableNotebookHistoryDiffing":true,"branch":"2.33.220","accountsLimit":-1,"enableX509Authentication":false,"enableNotebookGitBranching":true,"local":false,"enableClusterAutoScalingForJobs":false,"enableStrongPassword":false,"displayDefaultContainerMemoryGB":30,"disableS3TableImport":false,"deploymentMode":"production","useSpotForWorkers":true,"enableUserInviteWorkflow":true,"enableStaticNotebooks":true,"enableCssTransitions":true,"minClusterTagKeyLength":1,"showHomepageFeaturedLinks":true,"pricingURL":"https://databricks.com/product/pricing","enableClusterAclsConfig":true,"useTempS3UrlForTableUpload":false,"notifyLastLogin":false,"enableNotebookGitVersioning":true,"files":"files/","feedbackEmail":"support@databricks.com","enableDriverLogsUI":true,"disableLegacyDashboards":false,"enableWorkspaceAclsConfig":true,"dropzoneMaxFileSize":4096,"enableNewClustersList":false,"enableNewDashboardViews":true,"driverLog4jFilePrefix":"log4j","enableSingleSignOn":true,"enableMavenLibraries":true,"displayRowLimit":1000,"deltaProcessingAsyncEnabled":true,"defaultSparkVersion":{"key":"2.0.x-scala2.10","displayName":"Spark 2.0 (Auto-updating, Scala 2.10)","packageLabel":"spark-image-4f22a8d3016bc3dce9e839b10418815a7d28afff3a027b43bd2b041c42b2a89d","upgradable":true,"deprecated":false,"customerVisible":true},"enableCustomSpotPricing":true,"enableMountAclsConfig":false,"useDevTierHomePage":false,"enablePublishHub":false,"notebookHubUrl":"http://hub.dev.databricks.com/","showSqlEndpoints":true,"enableClusterAclsByTier":true,"databricksDocsBaseUrl":"https://docs.databricks.com/","disallowAddingAdmins":false,"enableSparkConfUI":true,"featureTier":"UNKNOWN_TIER","enableOrgSwitcherUI":false,"clustersLimit":-1,"enableJdbcImport":true,"logfiles":"logfiles/","enableWebappSharding":false,"enableClusterDeltaUpdates":true,"enableSingleSignOnLogin":false,"ebsVolumeSizeLimitGB":{"GENERAL_PURPOSE_SSD":[100,4096],"THROUGHPUT_OPTIMIZED_HDD":[500,4096]},"enableMountAcls":false,"requireEmailUserName":true,"enableDashboardViews":false,"dbcFeedbackURL":"http://feedback.databricks.com/forums/263785-product-feedback","enableMountAclService":true,"enableWorkspaceAcls":true,"maxClusterTagKeyLength":127,"gitHash":"8719902676c4e1cefbc31755c1726979bdf286d0","showWorkspaceFeaturedLinks":true,"signupUrl":"https://databricks.com/try-databricks","allowFeedbackForumAccess":true,"enableImportFromUrl":true,"enableMiniClusters":false,"enableDebugUI":false,"allowNonAdminUsers":true,"enableSingleSignOnByTier":true,"enableJobsRetryOnTimeout":true,"staticNotebookResourceUrl":"https://databricks-prod-cloudfront.cloud.databricks.com/static/e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855/","enableSparkPackages":true,"dynamicSparkVersions":true,"enableNotebookHistoryUI":true,"showDebugCounters":false,"enableInstanceProfilesUI":true,"enableFolderHtmlExport":true,"enableSparkVersionsUI":true,"homepageFeaturedLinks":[{"linkURI":"https://docs.databricks.com/_static/notebooks/gentle-introduction-to-apache-spark.html","displayName":"Introduction to Apache Spark on Databricks","icon":"img/home/Python_icon.svg"},{"linkURI":"https://docs.databricks.com/_static/notebooks/databricks-for-data-scientists.html","displayName":"Databricks for Data Scientists","icon":"img/home/Scala_icon.svg"},{"linkURI":"https://docs.databricks.com/_static/notebooks/structured-streaming-python.html","displayName":"Introduction to Structured Streaming","icon":"img/home/Python_icon.svg"}],"upgradeURL":"","notebookLoadingBackground":"#fff","sshContainerForwardedPort":2200,"enableServerAutoComplete":true,"enableStaticHtmlImport":true,"enableInstanceProfilesByTier":true,"enableTerminal":false,"defaultMemoryPerContainerMB":28000,"enablePresenceUI":true,"accounts":true,"useFramedStaticNotebooks":false,"enableNewProgressReportUI":true,"defaultCoresPerContainer":4,"enableNewClustersGet":false,"showSqlProxyUI":true};</script>
<script>var __DATABRICKS_NOTEBOOK_MODEL = {"version":"NotebookV1","origId":431,"name":"jlitven@gmail.com / spark_ML","language":"python","commands":[{"version":"CommandV1","origId":433,"guid":"a4001f07-7eb8-45ae-9ffc-c19f82be8506","subtype":"command","commandType":"auto","position":0.0,"command":"%md <img src=\"http://spark-mooc.github.io/web-assets/images/ta_Spark-logo-small.png\" align=left>\n<img src=\"http://spark-mooc.github.io/web-assets/images/python-logo-master-v3-TM-flattened_small.png\" align=left>","commandVersion":1,"state":"finished","results":{"type":"raw","data":"","arguments":{}},"errorSummary":null,"error":null,"workflows":[],"startTime":0.0,"submitTime":0.0,"finishTime":0.0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":{},"streamStates":{},"nuid":"9d6c5608-27a4-4be0-bca9-58ad44b22d9d"},{"version":"CommandV1","origId":434,"guid":"71d8f535-58ad-4922-9f65-00aa1f88c764","subtype":"command","commandType":"auto","position":1.0,"command":"%md # Spark Tutorial: Machine Learning\n\nMLlib is Spark's machine learning (ML) library. Its goal is to make practical machine learning scalable and easy. At a high level, it provides tools such as:\n\n* ML Algorithms: common learning algorithms such as classification, regression, clustering, and collaborative filtering\n* Featurization: feature extraction, transformation, dimensionality reduction, and selection\n* Pipelines: tools for constructing, evaluating, and tuning ML Pipelines\n* Persistence: saving and load algorithms, models, and Pipelines\n* Utilities: linear algebra, statistics, data handling, etc.\n\n## Spark Machine Learning Workflow\n\nInspired by the `scikit-learn` project, `MLlib` standardizes APIs for machine learning algorithms to make it easier to combine multiple algorithms into a single pipeline, or workflow.\n\n* **DataFrame**: This ML API uses DataFrame from Spark SQL as an ML dataset. A DataFrame could have different columns storing text, feature vectors, true labels, and predictions.\n\n* **Transformer**: A Transformer is an algorithm which can transform one DataFrame into another DataFrame.\n  * A feature transformer might take a DataFrame, read a column (e.g., text), map it into a new column (e.g., feature vectors), and output a new DataFrame with the mapped column appended.\n  * A learning model might take a DataFrame, read the column containing feature vectors, predict the label for each feature vector, and output a new DataFrame with predicted labels appended as a column.\n\n* **Estimator**: An Estimator is an algorithm which can be fit on a DataFrame to produce a Transformer. \n  * a learning algorithm such as LogisticRegression is an Estimator, and calling fit() trains a LogisticRegressionModel, which is a Model and hence a Transformer.\n\n* **Pipeline**: A Pipeline chains multiple Transformers and Estimators together to specify an ML workflow.\n\n* **Parameter**: All Transformers and Estimators now share a common API for specifying parameters.\n\n## How a ML Pipeline Works\n\n* A Pipeline is specified as a sequence of stages, and each stage is either a Transformer or an Estimator. \n* Stages are run in order, and the input DataFrame is transformed as it passes through each stage. \n* For Transformer stages, the `transform()` method is called on the DataFrame. \n* For Estimator stages, the `fit()` method is called to produce a Transformer (which becomes part of the `PipelineModel`, or fitted Pipeline), and that Transformer's `transform()` method is called on the DataFrame.","commandVersion":1,"state":"finished","results":{"type":"raw","data":"","arguments":{}},"errorSummary":null,"error":null,"workflows":[],"startTime":0.0,"submitTime":0.0,"finishTime":0.0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":{},"streamStates":{},"nuid":"23482c80-f392-48a7-b6b1-b0ca1345b8c4"},{"version":"CommandV1","origId":435,"guid":"0f74ab89-9ce3-44e6-8309-2cea9c4a2d31","subtype":"command","commandType":"auto","position":2.0,"command":"# Run this cell to setup data path\nimport os\n\ndataPath = os.getcwd()\nif dataPath.find('databricks') != -1:\n    ACCESS_KEY = \"AKIAI2P5MSEO2JYXJVQQ\"\n    SECRET_KEY = \"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\"\n    AWS_BUCKET_NAME = \"nycdsabootcamp\"\n    dataPath = \"s3a://%s:%s@%s/\" %(ACCESS_KEY, SECRET_KEY, AWS_BUCKET_NAME)","commandVersion":1,"state":"finished","results":{"type":"html","data":"<div class=\"ansiout\"></div>","arguments":{},"addedWidgets":{},"removedWidgets":[]},"errorSummary":null,"error":null,"workflows":[],"startTime":1.481512277219E12,"submitTime":1.481512278346E12,"finishTime":1.481512277257E12,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":{"collapsed":false},"streamStates":{},"nuid":"e6ddaa49-cb51-49c1-921d-9651a2557528"},{"version":"CommandV1","origId":436,"guid":"8f1bd84f-ef46-437a-a251-4874297ac26f","subtype":"command","commandType":"auto","position":3.0,"command":"%md ## ML Pipeline Example: Predicting Diamonds Price\n\nWe will be using diamonds dataset as an example to illustrate how to use pipeline. Here is an outline:\n\n* *Loading data to DataFrame*: Load data as DataFrame\n* *EDA*: Compute statistics and create visualizations to get a better understanding of the data.\n* *Train validation split*: Split the data randomly into training and test sets.  We will not look at the test data until *after* learning.\n* On the training dataset:\n  * *Extract features*: We will index categorical (String-valued) features so that DecisionTree can handle them.\n  * *Learn a model*: Run DecisionTree to learn how to predict a diamond's price from a description of the diamond.\n  * *Tune the model*: Tune the tree depth (complexity) using the training data.  (This process is also called *model selection*.)\n* *Evaluate the model*: Now look at the test dataset.  Compare the initial model with the tuned model to see the benefit of tuning parameters.\n* *Understand the model*: We will examine the learned model and results to gain further insight.","commandVersion":1,"state":"finished","results":{"type":"raw","data":"","arguments":{}},"errorSummary":null,"error":null,"workflows":[],"startTime":0.0,"submitTime":0.0,"finishTime":0.0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":{},"streamStates":{},"nuid":"0dcf08cc-f5ce-49fb-af88-077020515726"},{"version":"CommandV1","origId":437,"guid":"81b7192f-0ac4-4ce8-a1dc-0651f5fb0878","subtype":"command","commandType":"auto","position":4.0,"command":"%md ### Loading Data to DataFrame","commandVersion":1,"state":"finished","results":{"type":"raw","data":"","arguments":{}},"errorSummary":null,"error":null,"workflows":[],"startTime":0.0,"submitTime":0.0,"finishTime":0.0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":{},"streamStates":{},"nuid":"4a3ad655-4770-4758-ac3f-565e7564a60c"},{"version":"CommandV1","origId":438,"guid":"dc69c0b4-7763-4155-9f57-7d069fb3a283","subtype":"command","commandType":"auto","position":5.0,"command":"# diamondsDF.write.parquet(savePath, mode=\"overwrite\")\n# Apache Parquet is a columnar storage format available to any project in the Hadoop ecosystem, \n# regardless of the choice of data processing framework, data model or programming language.\ndiamondPath = os.path.join(dataPath, \"pyspark_3/diamonds\")\ndiamondsDF = spark.read.parquet(diamondPath)","commandVersion":1,"state":"finished","results":{"type":"html","data":"<div class=\"ansiout\"></div>","arguments":{},"addedWidgets":{},"removedWidgets":[]},"errorSummary":"<span class=\"ansired\">NameError</span>: name &apos;os&apos; is not defined","error":"<div class=\"ansiout\"><span class=\"ansired\">---------------------------------------------------------------------------</span>\n<span class=\"ansired\">NameError</span>                                 Traceback (most recent call last)\n<span class=\"ansigreen\">&lt;ipython-input-4-8f2f446e2131&gt;</span> in <span class=\"ansicyan\">&lt;module&gt;</span><span class=\"ansiblue\">()</span>\n<span class=\"ansigreen\">      2</span> <span class=\"ansired\"># Apache Parquet is a columnar storage format available to any project in the Hadoop ecosystem,</span><span class=\"ansiyellow\"></span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">      3</span> <span class=\"ansired\"># regardless of the choice of data processing framework, data model or programming language.</span><span class=\"ansiyellow\"></span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">----&gt; 4</span><span class=\"ansiyellow\"> </span>diamondPath <span class=\"ansiyellow\">=</span> os<span class=\"ansiyellow\">.</span>path<span class=\"ansiyellow\">.</span>join<span class=\"ansiyellow\">(</span>dataPath<span class=\"ansiyellow\">,</span> <span class=\"ansiblue\">&quot;pyspark_3/diamonds&quot;</span><span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">      5</span> diamondsDF <span class=\"ansiyellow\">=</span> spark<span class=\"ansiyellow\">.</span>read<span class=\"ansiyellow\">.</span>parquet<span class=\"ansiyellow\">(</span>diamondPath<span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n\n<span class=\"ansired\">NameError</span>: name &apos;os&apos; is not defined\n</div>","workflows":[],"startTime":1.481512283462E12,"submitTime":1.481512284584E12,"finishTime":1.481512285171E12,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":{"collapsed":false},"streamStates":{},"nuid":"921212d0-7f47-493d-91cd-ac6cfb054994"},{"version":"CommandV1","origId":439,"guid":"d584d86d-8174-47d6-ab2f-f322982fb3fd","subtype":"command","commandType":"auto","position":6.0,"command":"print diamondsDF.rdd.getNumPartitions()","commandVersion":1,"state":"finished","results":{"type":"html","data":"<div class=\"ansiout\">1\n</div>","arguments":{},"addedWidgets":{},"removedWidgets":[]},"errorSummary":null,"error":null,"workflows":[],"startTime":1.481512285339E12,"submitTime":1.481512286401E12,"finishTime":1.481512285509E12,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":{},"streamStates":{},"nuid":"5f6e1cfb-46ef-4e75-b275-550510934ab6"},{"version":"CommandV1","origId":440,"guid":"dc88428e-158d-40aa-b9d8-4a8b89cbdb31","subtype":"command","commandType":"auto","position":7.0,"command":"diamondsDF = spark.createDataFrame(diamondsDF.rdd.repartition(8))","commandVersion":1,"state":"finished","results":{"type":"html","data":"<div class=\"ansiout\"></div>","arguments":{},"addedWidgets":{},"removedWidgets":[]},"errorSummary":null,"error":null,"workflows":[],"startTime":1.481512286881E12,"submitTime":1.481512287975E12,"finishTime":1.481512288591E12,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":{},"streamStates":{},"nuid":"7a896e19-4beb-42de-b910-70070b5023eb"},{"version":"CommandV1","origId":441,"guid":"155b3a9a-08f2-449c-ad62-fe5582b81fdc","subtype":"command","commandType":"auto","position":8.0,"command":"diamondsDF.show()","commandVersion":1,"state":"finished","results":{"type":"html","data":"<div class=\"ansiout\">+-----+---------+-----+-------+-----+-----+------+----+----+----+\n|carat|      cut|color|clarity|depth|table| price|   x|   y|   z|\n+-----+---------+-----+-------+-----+-----+------+----+----+----+\n| 0.29|  Premium|    I|    VS2| 62.4| 58.0| 334.0| 4.2|4.23|2.63|\n| 0.31|     Good|    J|    SI2| 63.3| 58.0| 335.0|4.34|4.35|2.75|\n| 0.24|Very Good|    J|   VVS2| 62.8| 57.0| 336.0|3.94|3.96|2.48|\n| 0.24|Very Good|    I|   VVS1| 62.3| 57.0| 336.0|3.95|3.98|2.47|\n| 0.72|    Ideal|    D|    SI1| 61.9| 55.0|2903.0|5.78|5.75|3.57|\n| 0.72|  Premium|    D|    SI1| 61.4| 59.0|2903.0|5.79|5.71|3.53|\n| 0.72|  Premium|    E|    VS2| 61.1| 59.0|2903.0| 5.8|5.75|3.53|\n| 0.79|Very Good|    F|    SI1| 63.0| 54.0|2904.0|5.91|5.94|3.73|\n| 0.79|Very Good|    D|    SI2| 62.8| 57.0|2904.0|5.85| 5.9|3.69|\n|  0.7|Very Good|    E|    VS1| 58.4| 59.0|2904.0|5.83|5.91|3.43|\n| 0.62|    Ideal|    E|   VVS2| 62.0| 56.0|2904.0|5.48|5.52|3.41|\n|  0.7|Very Good|    G|   VVS2| 59.3| 62.0|2905.0|5.78|5.82|3.44|\n|  0.7|Very Good|    G|   VVS2| 63.4| 59.0|2905.0|5.62|5.64|3.57|\n|  0.7|Very Good|    G|   VVS2| 63.3| 59.0|2905.0|5.59|5.62|3.55|\n| 0.71|Very Good|    G|    VS2| 62.1| 58.0|2905.0|5.65|5.71|3.53|\n| 0.86|Very Good|    I|    VS1| 61.2| 58.0|2905.0| 6.1|6.16|3.75|\n| 0.53|    Ideal|    D|   VVS1| 62.5| 54.0|2905.0|5.16|5.21|3.24|\n| 0.91|Very Good|    J|    SI1| 63.5| 58.0|2905.0|6.17|6.12| 3.9|\n| 0.95|     Good|    I|    SI2| 63.8| 57.0|2905.0|6.23|6.13|3.94|\n| 0.91|  Premium|    J|    SI1| 62.8| 59.0|2905.0|6.19|6.14|3.87|\n+-----+---------+-----+-------+-----+-----+------+----+----+----+\nonly showing top 20 rows\n\n</div>","arguments":{},"addedWidgets":{},"removedWidgets":[]},"errorSummary":null,"error":null,"workflows":[],"startTime":1.481512288595E12,"submitTime":1.481512288944E12,"finishTime":1.481512288766E12,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":{},"streamStates":{},"nuid":"30a172b9-3f95-4b0a-9a6f-35c358f99b26"},{"version":"CommandV1","origId":442,"guid":"192d6528-6fe0-4011-a0e6-ee88b4069fdd","subtype":"command","commandType":"auto","position":9.0,"command":"diamondsDF.printSchema()\ndiamondsDF.show(5)","commandVersion":1,"state":"finished","results":{"type":"html","data":"<div class=\"ansiout\">root\n |-- carat: double (nullable = true)\n |-- cut: string (nullable = true)\n |-- color: string (nullable = true)\n |-- clarity: string (nullable = true)\n |-- depth: double (nullable = true)\n |-- table: double (nullable = true)\n |-- price: double (nullable = true)\n |-- x: double (nullable = true)\n |-- y: double (nullable = true)\n |-- z: double (nullable = true)\n\n+-----+---------+-----+-------+-----+-----+------+----+----+----+\n|carat|      cut|color|clarity|depth|table| price|   x|   y|   z|\n+-----+---------+-----+-------+-----+-----+------+----+----+----+\n| 0.29|  Premium|    I|    VS2| 62.4| 58.0| 334.0| 4.2|4.23|2.63|\n| 0.31|     Good|    J|    SI2| 63.3| 58.0| 335.0|4.34|4.35|2.75|\n| 0.24|Very Good|    J|   VVS2| 62.8| 57.0| 336.0|3.94|3.96|2.48|\n| 0.24|Very Good|    I|   VVS1| 62.3| 57.0| 336.0|3.95|3.98|2.47|\n| 0.72|    Ideal|    D|    SI1| 61.9| 55.0|2903.0|5.78|5.75|3.57|\n+-----+---------+-----+-------+-----+-----+------+----+----+----+\nonly showing top 5 rows\n\n</div>","arguments":{},"addedWidgets":{},"removedWidgets":[]},"errorSummary":null,"error":null,"workflows":[],"startTime":1.481296126724E12,"submitTime":1.481296126412E12,"finishTime":1.481296126897E12,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":{"collapsed":false},"streamStates":{},"nuid":"8b241c12-dedf-4e68-8864-9b1d0886b0ae"},{"version":"CommandV1","origId":443,"guid":"e594b61c-b377-401b-acdb-af8910c5d19c","subtype":"command","commandType":"auto","position":10.0,"command":"%md ### EDA\n\nLet's explore the data to get a better understanding of what is in there.","commandVersion":1,"state":"finished","results":{"type":"raw","data":"","arguments":{}},"errorSummary":null,"error":null,"workflows":[],"startTime":0.0,"submitTime":0.0,"finishTime":0.0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":{},"streamStates":{},"nuid":"fb810411-0976-4c1a-adec-2efa5109dd7c"},{"version":"CommandV1","origId":444,"guid":"f47b071c-770d-4b43-8825-98b6dbba6dc9","subtype":"command","commandType":"auto","position":11.0,"command":"%md ### Exercise 1\n\n1.1 Show the summary of the continuous varialbes.\n\n1.2 Find the count of each class of the categorical variables\n\n1.3 (Optional) Visualize your finding. You can use `display()` if you're using databricks.\n\n1.4 Based on the data, what machine learning algorithm might be a better choice?","commandVersion":1,"state":"finished","results":{"type":"raw","data":"","arguments":{}},"errorSummary":null,"error":null,"workflows":[],"startTime":0.0,"submitTime":0.0,"finishTime":0.0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":{},"streamStates":{},"nuid":"d22f3351-a65a-45f5-ac2f-e5c1abf3d4b2"},{"version":"CommandV1","origId":445,"guid":"ebb1ca9b-a2f6-4032-acee-c1e419bb86dd","subtype":"command","commandType":"auto","position":12.0,"command":"# Your code goes here\ndiamondsDF.describe().show()\n\ndiamondsDF.groupBy(\"cut\").count().show()\ndiamondsDF.groupBy(\"color\").count().show()\ndiamondsDF.groupBy(\"clarity\").count().show()","commandVersion":1,"state":"finished","results":{"type":"html","data":"<div class=\"ansiout\">+-------+-------------------+------------------+------------------+-----------------+------------------+------------------+------------------+\n|summary|              carat|             depth|             table|            price|                 x|                 y|                 z|\n+-------+-------------------+------------------+------------------+-----------------+------------------+------------------+------------------+\n|  count|              53940|             53940|             53940|            53940|             53940|             53940|             53940|\n|   mean| 0.7979397478680335|  61.7494048943272|57.457183908045984|3932.799721913237| 5.731157211716723|5.7345259547645515|3.5387337782721686|\n| stddev|0.47401124440542164|1.4326213188336645|2.2344905628213287|3989.439738146364|1.1217607467924988|1.1421346741235603|0.7056988469499914|\n|    min|                0.2|              43.0|              43.0|            326.0|               0.0|               0.0|               0.0|\n|    max|               5.01|              79.0|              95.0|          18823.0|             10.74|              58.9|              31.8|\n+-------+-------------------+------------------+------------------+-----------------+------------------+------------------+------------------+\n\n+---------+-----+\n|      cut|count|\n+---------+-----+\n|  Premium|13791|\n|    Ideal|21551|\n|     Good| 4906|\n|     Fair| 1610|\n|Very Good|12082|\n+---------+-----+\n\n+-----+-----+\n|color|count|\n+-----+-----+\n|    F| 9542|\n|    E| 9797|\n|    D| 6775|\n|    J| 2808|\n|    G|11292|\n|    I| 5422|\n|    H| 8304|\n+-----+-----+\n\n+-------+-----+\n|clarity|count|\n+-------+-----+\n|   VVS2| 5066|\n|    SI1|13065|\n|     IF| 1790|\n|     I1|  741|\n|   VVS1| 3655|\n|    VS2|12258|\n|    SI2| 9194|\n|    VS1| 8171|\n+-------+-----+\n\n</div>","arguments":{},"addedWidgets":{},"removedWidgets":[]},"errorSummary":"<span class=\"ansired\">AttributeError</span>: &apos;DataFrame&apos; object has no attribute &apos;summary&apos;","error":"<div class=\"ansiout\"><span class=\"ansired\">---------------------------------------------------------------------------</span>\n<span class=\"ansired\">AttributeError</span>                            Traceback (most recent call last)\n<span class=\"ansigreen\">&lt;ipython-input-8-2551b21c33e4&gt;</span> in <span class=\"ansicyan\">&lt;module&gt;</span><span class=\"ansiblue\">()</span>\n<span class=\"ansigreen\">      2</span> diamondsDF<span class=\"ansiyellow\">.</span>describe<span class=\"ansiyellow\">(</span><span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">      3</span> <span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">----&gt; 4</span><span class=\"ansiyellow\"> </span>diamondsDF<span class=\"ansiyellow\">.</span>summary<span class=\"ansiyellow\">(</span><span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n\n<span class=\"ansigreen\">/databricks/spark/python/pyspark/sql/dataframe.py</span> in <span class=\"ansicyan\">__getattr__</span><span class=\"ansiblue\">(self, name)</span>\n<span class=\"ansigreen\">    856</span>         <span class=\"ansigreen\">if</span> name <span class=\"ansigreen\">not</span> <span class=\"ansigreen\">in</span> self<span class=\"ansiyellow\">.</span>columns<span class=\"ansiyellow\">:</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">    857</span>             raise AttributeError(\n<span class=\"ansigreen\">--&gt; 858</span><span class=\"ansiyellow\">                 &quot;&apos;%s&apos; object has no attribute &apos;%s&apos;&quot; % (self.__class__.__name__, name))\n</span><span class=\"ansigreen\">    859</span>         jc <span class=\"ansiyellow\">=</span> self<span class=\"ansiyellow\">.</span>_jdf<span class=\"ansiyellow\">.</span>apply<span class=\"ansiyellow\">(</span>name<span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">    860</span>         <span class=\"ansigreen\">return</span> Column<span class=\"ansiyellow\">(</span>jc<span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n\n<span class=\"ansired\">AttributeError</span>: &apos;DataFrame&apos; object has no attribute &apos;summary&apos;\n</div>","workflows":[],"startTime":1.481296681774E12,"submitTime":1.481296681448E12,"finishTime":1.481296685699E12,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":{"collapsed":false},"streamStates":{},"nuid":"97ad94c0-090f-4a7a-9e27-11df69790933"},{"version":"CommandV1","origId":446,"guid":"a440201d-5c1b-4f3d-8956-8d4365434a98","subtype":"command","commandType":"auto","position":13.0,"command":"%md ### Extracting, transforming and selecting features\n\nWe now want to use Decision Tree Algorithm, which handles both continuous features (e.g., \"carat\") and categorical features (e.g., \"cut\"). However, Decision Tree requires that categorical features be indexed as integers, i.e., {0, 1, 2, ..., numberOfCategories - 1}.\n\n**StringIndexer**\n\n`StringIndexer` encodes a string column of labels to a column of label indices. The indices are in [0, `numLabels`), ordered by label frequencies, so the most frequent label gets index 0.\n\nThe example below shows how `StringIndexer` \"encodes\" the `cut` column.\n\n**OneHotEncoder**\n\nOne-hot encoding maps a column of label indices to a column of binary vectors, with at most a single one-value. This encoding allows algorithms which expect continuous features, such as Logistic Regression, to use categorical features.","commandVersion":1,"state":"finished","results":{"type":"raw","data":"","arguments":{}},"errorSummary":null,"error":null,"workflows":[],"startTime":0.0,"submitTime":0.0,"finishTime":0.0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":{},"streamStates":{},"nuid":"fb8f0d63-4ee0-4222-81e4-12d7c2a38da7"},{"version":"CommandV1","origId":447,"guid":"058108f1-1b54-4483-be7c-9b70c7b5810d","subtype":"command","commandType":"auto","position":14.0,"command":"from pyspark.ml.feature import OneHotEncoder, StringIndexer\n\nindexer = StringIndexer(inputCol=\"cut\", outputCol=\"cutIndex\")\nindexed = indexer.fit(diamondsDF).transform(diamondsDF)\nindexed.show(5)\nencoder = OneHotEncoder(inputCol = \"cutIndex\", outputCol = \"cutclassVec\")\nencoded = encoder.transform(indexed)\nencoded.show(5)","commandVersion":1,"state":"finished","results":{"type":"html","data":"<div class=\"ansiout\">+-----+---------+-----+-------+-----+-----+------+----+----+----+--------+\n|carat|      cut|color|clarity|depth|table| price|   x|   y|   z|cutIndex|\n+-----+---------+-----+-------+-----+-----+------+----+----+----+--------+\n| 0.29|  Premium|    I|    VS2| 62.4| 58.0| 334.0| 4.2|4.23|2.63|     1.0|\n| 0.31|     Good|    J|    SI2| 63.3| 58.0| 335.0|4.34|4.35|2.75|     3.0|\n| 0.24|Very Good|    J|   VVS2| 62.8| 57.0| 336.0|3.94|3.96|2.48|     2.0|\n| 0.24|Very Good|    I|   VVS1| 62.3| 57.0| 336.0|3.95|3.98|2.47|     2.0|\n| 0.72|    Ideal|    D|    SI1| 61.9| 55.0|2903.0|5.78|5.75|3.57|     0.0|\n+-----+---------+-----+-------+-----+-----+------+----+----+----+--------+\nonly showing top 5 rows\n\n+-----+---------+-----+-------+-----+-----+------+----+----+----+--------+-------------+\n|carat|      cut|color|clarity|depth|table| price|   x|   y|   z|cutIndex|  cutclassVec|\n+-----+---------+-----+-------+-----+-----+------+----+----+----+--------+-------------+\n| 0.29|  Premium|    I|    VS2| 62.4| 58.0| 334.0| 4.2|4.23|2.63|     1.0|(4,[1],[1.0])|\n| 0.31|     Good|    J|    SI2| 63.3| 58.0| 335.0|4.34|4.35|2.75|     3.0|(4,[3],[1.0])|\n| 0.24|Very Good|    J|   VVS2| 62.8| 57.0| 336.0|3.94|3.96|2.48|     2.0|(4,[2],[1.0])|\n| 0.24|Very Good|    I|   VVS1| 62.3| 57.0| 336.0|3.95|3.98|2.47|     2.0|(4,[2],[1.0])|\n| 0.72|    Ideal|    D|    SI1| 61.9| 55.0|2903.0|5.78|5.75|3.57|     0.0|(4,[0],[1.0])|\n+-----+---------+-----+-------+-----+-----+------+----+----+----+--------+-------------+\nonly showing top 5 rows\n\n</div>","arguments":{},"addedWidgets":{},"removedWidgets":[]},"errorSummary":null,"error":null,"workflows":[],"startTime":1.481297189071E12,"submitTime":1.481297188739E12,"finishTime":1.481297191089E12,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":{"collapsed":false},"streamStates":{},"nuid":"d068af17-8ef3-4af9-ae91-fb85e09f658f"},{"version":"CommandV1","origId":448,"guid":"0bb1e227-37da-44be-8137-48382f9aec83","subtype":"command","commandType":"auto","position":15.0,"command":"%md Now we want to create one-hot encoded features for all the three categorical variables and later will pass them into the pipeline.","commandVersion":1,"state":"finished","results":{"type":"raw","data":"","arguments":{}},"errorSummary":null,"error":null,"workflows":[],"startTime":0.0,"submitTime":0.0,"finishTime":0.0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":{},"streamStates":{},"nuid":"79d80aa1-0e13-41e5-aa57-53be3d45fac0"},{"version":"CommandV1","origId":449,"guid":"b0e14c19-698f-41d7-a2cf-9cc4b3943c57","subtype":"command","commandType":"auto","position":16.0,"command":"categoricalColumns = [\"cut\", \"color\", \"clarity\"]\nstages = [] # stages in our Pipeline\nfor categoricalCol in categoricalColumns:\n  # Category Indexing with StringIndexer\n  stringIndexer = StringIndexer(inputCol=categoricalCol, outputCol=categoricalCol+\"Index\")\n  # Use OneHotEncoder to convert categorical variables into binary SparseVectors\n  encoder = OneHotEncoder(inputCol=categoricalCol+\"Index\", outputCol=categoricalCol+\"classVec\")\n  # Add stages.  These are not run here, but will run all at once later on.\n  stages += [stringIndexer, encoder]","commandVersion":1,"state":"finished","results":{"type":"html","data":"<div class=\"ansiout\"></div>","arguments":{},"addedWidgets":{},"removedWidgets":[]},"errorSummary":null,"error":null,"workflows":[],"startTime":1.481300132678E12,"submitTime":1.481300132273E12,"finishTime":1.481300132749E12,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":{},"streamStates":{},"nuid":"b4936afd-de0c-4568-aef1-ed281181456b"},{"version":"CommandV1","origId":450,"guid":"549b06d3-5b5b-4ce1-9efd-700b73c501e7","subtype":"command","commandType":"auto","position":17.0,"command":"%md **VectorAssembler**\n\n`VectorAssembler` is a transformer that combines a given list of columns into a single vector column. It is useful for combining raw features and features generated by different feature transformers into a single feature vector, in order to train ML models like logistic regression and decision trees.","commandVersion":1,"state":"finished","results":{"type":"raw","data":"","arguments":{}},"errorSummary":null,"error":null,"workflows":[],"startTime":0.0,"submitTime":0.0,"finishTime":0.0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":{},"streamStates":{},"nuid":"4f0a67b6-991e-4cb4-a8b2-f623365de06a"},{"version":"CommandV1","origId":451,"guid":"0feac73a-cab2-4f24-83df-93128410543a","subtype":"command","commandType":"auto","position":18.0,"command":"from pyspark.ml.feature import VectorAssembler\n\nassembler = VectorAssembler(inputCols=[\"carat\", \"depth\", \"table\"], \n                            outputCol=\"features\")\n\noutput = assembler.transform(diamondsDF)\noutput.select(\"features\", \"price\").show(5)","commandVersion":1,"state":"finished","results":{"type":"html","data":"<div class=\"ansiout\">+----------------+------+\n|        features| price|\n+----------------+------+\n|[0.29,62.4,58.0]| 334.0|\n|[0.31,63.3,58.0]| 335.0|\n|[0.24,62.8,57.0]| 336.0|\n|[0.24,62.3,57.0]| 336.0|\n|[0.72,61.9,55.0]|2903.0|\n+----------------+------+\nonly showing top 5 rows\n\n</div>","arguments":{},"addedWidgets":{},"removedWidgets":[]},"errorSummary":null,"error":null,"workflows":[],"startTime":1.48130015825E12,"submitTime":1.481300157843E12,"finishTime":1.481300158622E12,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":{"collapsed":false},"streamStates":{},"nuid":"af53ccf6-b524-4157-b30b-2be37bb74528"},{"version":"CommandV1","origId":452,"guid":"0300a684-181c-4d1f-95a0-2921b5d88873","subtype":"command","commandType":"auto","position":19.0,"command":"# Use Vector Assembler to create Feature Vector\n# We wil pass these into our Pipeline later\nassembler = VectorAssembler(inputCols=[\"carat\", \n                                       \"cutclassVec\", \n                                       \"colorclassVec\", \n                                       \"clarityclassVec\", \n                                       \"depth\", \"table\", \n                                       \"x\", \"y\", \"z\"], \n                            outputCol=\"features\")","commandVersion":1,"state":"finished","results":{"type":"html","data":"<div class=\"ansiout\"></div>","arguments":{},"addedWidgets":{},"removedWidgets":[]},"errorSummary":null,"error":null,"workflows":[],"startTime":1.481300202695E12,"submitTime":1.481300202289E12,"finishTime":1.481300202766E12,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":{"collapsed":true},"streamStates":{},"nuid":"184af59b-a86e-4a26-a7cb-f06bbbac508b"},{"version":"CommandV1","origId":453,"guid":"360f3cb6-f6c8-45cd-81a7-fe42eeab04d5","subtype":"command","commandType":"auto","position":20.0,"command":"%md ### Train Validation Split\n\nWe randomly split the dataset into 2 parts: training Data (70%) and test Data (30%). We will do all of our learning and tuning on the training set and validate our model on the test set to avoid overfitting issue.","commandVersion":1,"state":"finished","results":{"type":"raw","data":"","arguments":{}},"errorSummary":null,"error":null,"workflows":[],"startTime":0.0,"submitTime":0.0,"finishTime":0.0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":{},"streamStates":{},"nuid":"8c836cab-b11a-4356-8643-8b2b7ae91852"},{"version":"CommandV1","origId":454,"guid":"e95f03fc-25b5-425c-8379-07484ea727a8","subtype":"command","commandType":"auto","position":21.0,"command":"# Split data approximately into training (70%) and test (30%)\ntraining, test = diamondsDF.randomSplit([0.7, 0.3])\n\n# Cache the training and test datasets.\ntraining.cache()\ntest.cache()","commandVersion":1,"state":"finished","results":{"type":"html","data":"<div class=\"ansiout\"><span class=\"ansired\">Out[</span><span class=\"ansired\">16</span><span class=\"ansired\">]: </span>DataFrame[carat: double, cut: string, color: string, clarity: string, depth: double, table: double, price: double, x: double, y: double, z: double]\n</div>","arguments":{},"addedWidgets":{},"removedWidgets":[]},"errorSummary":null,"error":null,"workflows":[],"startTime":1.481300205305E12,"submitTime":1.481300204885E12,"finishTime":1.481300205477E12,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":{"collapsed":false},"streamStates":{},"nuid":"6d0ea823-e7f3-4c66-bd94-87741785f88d"},{"version":"CommandV1","origId":455,"guid":"d9c48289-ea4f-4d00-9808-4ac26b9e50c6","subtype":"command","commandType":"auto","position":22.0,"command":"print \"Training set size: \", training.count()\nprint \"Validation set size: \", test.count()","commandVersion":1,"state":"finished","results":{"type":"html","data":"<div class=\"ansiout\">Training set size:  37990\nValidation set size:  15950\n</div>","arguments":{},"addedWidgets":{},"removedWidgets":[]},"errorSummary":null,"error":null,"workflows":[],"startTime":1.481300212183E12,"submitTime":1.481300211777E12,"finishTime":1.481300213895E12,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":{"collapsed":false},"streamStates":{},"nuid":"0b989495-169d-4bcd-ac1d-793406d7eb04"},{"version":"CommandV1","origId":456,"guid":"25875f88-f95e-4d2e-a4c5-2497450b9280","subtype":"command","commandType":"auto","position":23.0,"command":"%md ### Training a DecisionTree model\n\nNow we have our training data and we will train a Regression Tree model by chaining all the estimators with a pipeline. This will create a pipeline estimator.","commandVersion":1,"state":"finished","results":{"type":"raw","data":"","arguments":{}},"errorSummary":null,"error":null,"workflows":[],"startTime":0.0,"submitTime":0.0,"finishTime":0.0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":{},"streamStates":{},"nuid":"0f4cb6c2-0daa-4711-a557-1c8d79104d61"},{"version":"CommandV1","origId":457,"guid":"7093b8b0-1899-4dd7-a491-d89dd873ccc5","subtype":"command","commandType":"auto","position":24.0,"command":"from pyspark.ml.regression import DecisionTreeRegressor\nfrom pyspark.ml import Pipeline\n\n# Train a DecisionTree model.\ndt = DecisionTreeRegressor(labelCol=\"price\", featuresCol=\"features\")\n\n# Chain indexer and tree in a Pipeline\npipeline = Pipeline(stages = stages + [assembler, dt])\n\n# Train model. This also runs the indexer.\nmodel = pipeline.fit(training)","commandVersion":1,"state":"finished","results":{"type":"html","data":"<div class=\"ansiout\"></div>","arguments":{},"addedWidgets":{},"removedWidgets":[]},"errorSummary":null,"error":null,"workflows":[],"startTime":1.481300567464E12,"submitTime":1.481300567037E12,"finishTime":1.481300568873E12,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":{"collapsed":false},"streamStates":{},"nuid":"bc759721-9b69-4ef4-a4d5-555a2a7ce4a1"},{"version":"CommandV1","origId":458,"guid":"85f44c85-6bd9-4853-bbe5-aa3649f476ea","subtype":"command","commandType":"auto","position":25.0,"command":"%md ### Model Evaluation","commandVersion":1,"state":"finished","results":{"type":"raw","data":"","arguments":{}},"errorSummary":null,"error":null,"workflows":[],"startTime":0.0,"submitTime":0.0,"finishTime":0.0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":{},"streamStates":{},"nuid":"ba17a9a4-6f76-4914-9710-8fb623a9a49d"},{"version":"CommandV1","origId":459,"guid":"479ee0c6-1e70-48bf-a0c7-86c47dbe5088","subtype":"command","commandType":"auto","position":26.0,"command":"%md A Pipeline is an Estimator. Thus, after a Pipeline's `fit()` method runs, it produces a `PipelineModel`, which is a `Transformer`.","commandVersion":1,"state":"finished","results":{"type":"raw","data":"","arguments":{}},"errorSummary":null,"error":null,"workflows":[],"startTime":0.0,"submitTime":0.0,"finishTime":0.0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":{},"streamStates":{},"nuid":"391be4be-c50a-492c-96dc-27dbcf29d363"},{"version":"CommandV1","origId":460,"guid":"e30da5cb-6992-4e47-841b-54b289119b28","subtype":"command","commandType":"auto","position":27.0,"command":"# Make predictions.\npredictions = model.transform(test)\n\npredictions.printSchema()\npredictions.select(\"features\", \"price\",\"prediction\")\\\n    .show(10)","commandVersion":1,"state":"finished","results":{"type":"html","data":"<div class=\"ansiout\">root\n |-- carat: double (nullable = true)\n |-- cut: string (nullable = true)\n |-- color: string (nullable = true)\n |-- clarity: string (nullable = true)\n |-- depth: double (nullable = true)\n |-- table: double (nullable = true)\n |-- price: double (nullable = true)\n |-- x: double (nullable = true)\n |-- y: double (nullable = true)\n |-- z: double (nullable = true)\n |-- cutIndex: double (nullable = true)\n |-- cutclassVec: vector (nullable = true)\n |-- colorIndex: double (nullable = true)\n |-- colorclassVec: vector (nullable = true)\n |-- clarityIndex: double (nullable = true)\n |-- clarityclassVec: vector (nullable = true)\n |-- features: vector (nullable = true)\n |-- prediction: double (nullable = true)\n\n+--------------------+-----+-----------------+\n|            features|price|       prediction|\n+--------------------+-----+-----------------+\n|(23,[0,1,5,17,18,...|559.0|588.8877901977644|\n|(23,[0,4,7,14,18,...|558.0|588.8877901977644|\n|(23,[0,2,6,14,18,...|558.0|588.8877901977644|\n|(23,[0,2,6,14,18,...|558.0|588.8877901977644|\n|(23,[0,2,7,14,18,...|558.0|588.8877901977644|\n|(23,[0,3,7,17,18,...|560.0|588.8877901977644|\n|(23,[0,1,6,13,18,...|558.0| 744.867019517036|\n|(23,[0,1,6,13,18,...|558.0| 744.867019517036|\n|(23,[0,1,5,13,18,...|558.0| 744.867019517036|\n|(23,[0,2,6,13,18,...|558.0| 744.867019517036|\n+--------------------+-----+-----------------+\nonly showing top 10 rows\n\n</div>","arguments":{},"addedWidgets":{},"removedWidgets":[]},"errorSummary":null,"error":null,"workflows":[],"startTime":1.481300668456E12,"submitTime":1.481300668034E12,"finishTime":1.481300668729E12,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":{"collapsed":false},"streamStates":{},"nuid":"d4808bae-c5a7-47a8-95ca-6f7976c03dec"},{"version":"CommandV1","origId":461,"guid":"58b04e8d-9904-4312-8fbd-b46732ce699c","subtype":"command","commandType":"auto","position":28.0,"command":"%md We now can compute the error using the `RegressionEvaluator`. We will choose Root Mean Squared Error (RMSE) as the error metric.","commandVersion":1,"state":"finished","results":{"type":"raw","data":"","arguments":{}},"errorSummary":null,"error":null,"workflows":[],"startTime":0.0,"submitTime":0.0,"finishTime":0.0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":{},"streamStates":{},"nuid":"c0e6e9b3-1e8a-4056-b598-3eb9e4aebac8"},{"version":"CommandV1","origId":462,"guid":"448e1997-4f84-4025-b835-9ca5170eb0ed","subtype":"command","commandType":"auto","position":29.0,"command":"from pyspark.ml.evaluation import RegressionEvaluator\n\n# Select (prediction, true label) and compute test error\nevaluator = RegressionEvaluator(labelCol=\"price\", \n                                predictionCol=\"prediction\", \n                                metricName=\"rmse\")\nrmse = evaluator.evaluate(predictions)\nprint(\"Root Mean Squared Error (RMSE) on test data = %g\" % rmse)","commandVersion":1,"state":"finished","results":{"type":"html","data":"<div class=\"ansiout\">Root Mean Squared Error (RMSE) on test data = 1281.71\n</div>","arguments":{},"addedWidgets":{},"removedWidgets":[]},"errorSummary":null,"error":null,"workflows":[],"startTime":1.481301784983E12,"submitTime":1.481301784533E12,"finishTime":1.481301785164E12,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":{"collapsed":false},"streamStates":{},"nuid":"28f23eed-e157-44c8-ae23-e5ff54c75c65"},{"version":"CommandV1","origId":463,"guid":"3d6bac67-884e-4dc1-ab90-1a7d529def5d","subtype":"command","commandType":"auto","position":30.0,"command":"%md ### Model Tuning\n\nThe `DecisionTreeRegressor` takes several parameters. We can try to tune those parameters to improve the accuracy or prevent overfitting on the training data.","commandVersion":1,"state":"finished","results":{"type":"raw","data":"","arguments":{}},"errorSummary":null,"error":null,"workflows":[],"startTime":0.0,"submitTime":0.0,"finishTime":0.0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":{},"streamStates":{},"nuid":"73b7d187-6c16-46d4-8b55-54473be950a0"},{"version":"CommandV1","origId":464,"guid":"371379c6-271c-4808-b49c-3fcc6ccbdb8e","subtype":"command","commandType":"auto","position":31.0,"command":"help(DecisionTreeRegressor)","commandVersion":1,"state":"finished","results":{"type":"html","data":"<div class=\"ansiout\">Help on class DecisionTreeRegressor in module pyspark.ml.regression:\n\nclass DecisionTreeRegressor(pyspark.ml.wrapper.JavaEstimator, pyspark.ml.param.shared.HasFeaturesCol, pyspark.ml.param.shared.HasLabelCol, pyspark.ml.param.shared.HasPredictionCol, pyspark.ml.param.shared.DecisionTreeParams, TreeRegressorParams, pyspark.ml.param.shared.HasCheckpointInterval, pyspark.ml.param.shared.HasSeed, pyspark.ml.util.JavaMLWritable, pyspark.ml.util.JavaMLReadable, pyspark.ml.param.shared.HasVarianceCol)\n |  &#96;Decision tree &lt;http://en.wikipedia.org/wiki/Decision_tree_learning&gt;&#96;_\n |  learning algorithm for regression.\n |  It supports both continuous and categorical features.\n |  \n |  &gt;&gt;&gt; from pyspark.ml.linalg import Vectors\n |  &gt;&gt;&gt; df = spark.createDataFrame([\n |  ...     (1.0, Vectors.dense(1.0)),\n |  ...     (0.0, Vectors.sparse(1, [], []))], [&quot;label&quot;, &quot;features&quot;])\n |  &gt;&gt;&gt; dt = DecisionTreeRegressor(maxDepth=2, varianceCol=&quot;variance&quot;)\n |  &gt;&gt;&gt; model = dt.fit(df)\n |  &gt;&gt;&gt; model.depth\n |  1\n |  &gt;&gt;&gt; model.numNodes\n |  3\n |  &gt;&gt;&gt; model.featureImportances\n |  SparseVector(1, {0: 1.0})\n |  &gt;&gt;&gt; test0 = spark.createDataFrame([(Vectors.dense(-1.0),)], [&quot;features&quot;])\n |  &gt;&gt;&gt; model.transform(test0).head().prediction\n |  0.0\n |  &gt;&gt;&gt; test1 = spark.createDataFrame([(Vectors.sparse(1, [0], [1.0]),)], [&quot;features&quot;])\n |  &gt;&gt;&gt; model.transform(test1).head().prediction\n |  1.0\n |  &gt;&gt;&gt; dtr_path = temp_path + &quot;/dtr&quot;\n |  &gt;&gt;&gt; dt.save(dtr_path)\n |  &gt;&gt;&gt; dt2 = DecisionTreeRegressor.load(dtr_path)\n |  &gt;&gt;&gt; dt2.getMaxDepth()\n |  2\n |  &gt;&gt;&gt; model_path = temp_path + &quot;/dtr_model&quot;\n |  &gt;&gt;&gt; model.save(model_path)\n |  &gt;&gt;&gt; model2 = DecisionTreeRegressionModel.load(model_path)\n |  &gt;&gt;&gt; model.numNodes == model2.numNodes\n |  True\n |  &gt;&gt;&gt; model.depth == model2.depth\n |  True\n |  &gt;&gt;&gt; model.transform(test1).head().variance\n |  0.0\n |  \n |  .. versionadded:: 1.4.0\n |  \n |  Method resolution order:\n |      DecisionTreeRegressor\n |      pyspark.ml.wrapper.JavaEstimator\n |      pyspark.ml.wrapper.JavaParams\n |      pyspark.ml.wrapper.JavaWrapper\n |      pyspark.ml.base.Estimator\n |      pyspark.ml.param.shared.HasFeaturesCol\n |      pyspark.ml.param.shared.HasLabelCol\n |      pyspark.ml.param.shared.HasPredictionCol\n |      pyspark.ml.param.shared.DecisionTreeParams\n |      TreeRegressorParams\n |      pyspark.ml.param.shared.HasCheckpointInterval\n |      pyspark.ml.param.shared.HasSeed\n |      pyspark.ml.util.JavaMLWritable\n |      pyspark.ml.util.MLWritable\n |      pyspark.ml.util.JavaMLReadable\n |      pyspark.ml.util.MLReadable\n |      pyspark.ml.param.shared.HasVarianceCol\n |      pyspark.ml.param.Params\n |      pyspark.ml.util.Identifiable\n |      __builtin__.object\n |  \n |  Methods defined here:\n |  \n |  __init__(*args, **kwargs)\n |      __init__(self, featuresCol=&quot;features&quot;, labelCol=&quot;label&quot;, predictionCol=&quot;prediction&quot;,                  maxDepth=5, maxBins=32, minInstancesPerNode=1, minInfoGain=0.0,                  maxMemoryInMB=256, cacheNodeIds=False, checkpointInterval=10,                  impurity=&quot;variance&quot;, seed=None, varianceCol=None)\n |  \n |  setParams(*args, **kwargs)\n |      setParams(self, featuresCol=&quot;features&quot;, labelCol=&quot;label&quot;, predictionCol=&quot;prediction&quot;,                   maxDepth=5, maxBins=32, minInstancesPerNode=1, minInfoGain=0.0,                   maxMemoryInMB=256, cacheNodeIds=False, checkpointInterval=10,                   impurity=&quot;variance&quot;, seed=None, varianceCol=None)\n |      Sets params for the DecisionTreeRegressor.\n |      \n |      .. versionadded:: 1.4.0\n |  \n |  ----------------------------------------------------------------------\n |  Data and other attributes defined here:\n |  \n |  __abstractmethods__ = frozenset([])\n |  \n |  ----------------------------------------------------------------------\n |  Data and other attributes inherited from pyspark.ml.wrapper.JavaEstimator:\n |  \n |  __metaclass__ = &lt;class &apos;abc.ABCMeta&apos;&gt;\n |      Metaclass for defining Abstract Base Classes (ABCs).\n |      \n |      Use this metaclass to create an ABC.  An ABC can be subclassed\n |      directly, and then acts as a mix-in class.  You can also register\n |      unrelated concrete classes (even built-in classes) and unrelated\n |      ABCs as &apos;virtual subclasses&apos; -- these and their descendants will\n |      be considered subclasses of the registering ABC by the built-in\n |      issubclass() function, but the registering ABC won&apos;t show up in\n |      their MRO (Method Resolution Order) nor will method\n |      implementations defined by the registering ABC be callable (not\n |      even via super()).\n |  \n |  ----------------------------------------------------------------------\n |  Data descriptors inherited from pyspark.ml.wrapper.JavaWrapper:\n |  \n |  __dict__\n |      dictionary for instance variables (if defined)\n |  \n |  __weakref__\n |      list of weak references to the object (if defined)\n |  \n |  ----------------------------------------------------------------------\n |  Methods inherited from pyspark.ml.base.Estimator:\n |  \n |  fit(self, dataset, params=None)\n |      Fits a model to the input dataset with optional parameters.\n |      \n |      :param dataset: input dataset, which is an instance of :py:class:&#96;pyspark.sql.DataFrame&#96;\n |      :param params: an optional param map that overrides embedded params. If a list/tuple of\n |                     param maps is given, this calls fit on each param map and returns a list of\n |                     models.\n |      :returns: fitted model(s)\n |      \n |      .. versionadded:: 1.3.0\n |  \n |  ----------------------------------------------------------------------\n |  Methods inherited from pyspark.ml.param.shared.HasFeaturesCol:\n |  \n |  getFeaturesCol(self)\n |      Gets the value of featuresCol or its default value.\n |  \n |  setFeaturesCol(self, value)\n |      Sets the value of :py:attr:&#96;featuresCol&#96;.\n |  \n |  ----------------------------------------------------------------------\n |  Data and other attributes inherited from pyspark.ml.param.shared.HasFeaturesCol:\n |  \n |  featuresCol = Param(parent=&apos;undefined&apos;, name=&apos;featuresCol&apos;, doc=&apos;featu...\n |  \n |  ----------------------------------------------------------------------\n |  Methods inherited from pyspark.ml.param.shared.HasLabelCol:\n |  \n |  getLabelCol(self)\n |      Gets the value of labelCol or its default value.\n |  \n |  setLabelCol(self, value)\n |      Sets the value of :py:attr:&#96;labelCol&#96;.\n |  \n |  ----------------------------------------------------------------------\n |  Data and other attributes inherited from pyspark.ml.param.shared.HasLabelCol:\n |  \n |  labelCol = Param(parent=&apos;undefined&apos;, name=&apos;labelCol&apos;, doc=&apos;label colum...\n |  \n |  ----------------------------------------------------------------------\n |  Methods inherited from pyspark.ml.param.shared.HasPredictionCol:\n |  \n |  getPredictionCol(self)\n |      Gets the value of predictionCol or its default value.\n |  \n |  setPredictionCol(self, value)\n |      Sets the value of :py:attr:&#96;predictionCol&#96;.\n |  \n |  ----------------------------------------------------------------------\n |  Data and other attributes inherited from pyspark.ml.param.shared.HasPredictionCol:\n |  \n |  predictionCol = Param(parent=&apos;undefined&apos;, name=&apos;predictionCol&apos;, doc=&apos;p...\n |  \n |  ----------------------------------------------------------------------\n |  Methods inherited from pyspark.ml.param.shared.DecisionTreeParams:\n |  \n |  getCacheNodeIds(self)\n |      Gets the value of cacheNodeIds or its default value.\n |  \n |  getMaxBins(self)\n |      Gets the value of maxBins or its default value.\n |  \n |  getMaxDepth(self)\n |      Gets the value of maxDepth or its default value.\n |  \n |  getMaxMemoryInMB(self)\n |      Gets the value of maxMemoryInMB or its default value.\n |  \n |  getMinInfoGain(self)\n |      Gets the value of minInfoGain or its default value.\n |  \n |  getMinInstancesPerNode(self)\n |      Gets the value of minInstancesPerNode or its default value.\n |  \n |  setCacheNodeIds(self, value)\n |      Sets the value of :py:attr:&#96;cacheNodeIds&#96;.\n |  \n |  setMaxBins(self, value)\n |      Sets the value of :py:attr:&#96;maxBins&#96;.\n |  \n |  setMaxDepth(self, value)\n |      Sets the value of :py:attr:&#96;maxDepth&#96;.\n |  \n |  setMaxMemoryInMB(self, value)\n |      Sets the value of :py:attr:&#96;maxMemoryInMB&#96;.\n |  \n |  setMinInfoGain(self, value)\n |      Sets the value of :py:attr:&#96;minInfoGain&#96;.\n |  \n |  setMinInstancesPerNode(self, value)\n |      Sets the value of :py:attr:&#96;minInstancesPerNode&#96;.\n |  \n |  ----------------------------------------------------------------------\n |  Data and other attributes inherited from pyspark.ml.param.shared.DecisionTreeParams:\n |  \n |  cacheNodeIds = Param(parent=&apos;undefined&apos;, name=&apos;cacheNodeIds&apos;, d...ed o...\n |  \n |  maxBins = Param(parent=&apos;undefined&apos;, name=&apos;maxBins&apos;, doc=&apos;M...mber of c...\n |  \n |  maxDepth = Param(parent=&apos;undefined&apos;, name=&apos;maxDepth&apos;, doc=&apos;...; depth ...\n |  \n |  maxMemoryInMB = Param(parent=&apos;undefined&apos;, name=&apos;maxMemoryInMB&apos;, ...ati...\n |  \n |  minInfoGain = Param(parent=&apos;undefined&apos;, name=&apos;minInfoGain&apos;, do...in fo...\n |  \n |  minInstancesPerNode = Param(parent=&apos;undefined&apos;, name=&apos;minInstancesPerN...\n |  \n |  ----------------------------------------------------------------------\n |  Methods inherited from TreeRegressorParams:\n |  \n |  getImpurity(self)\n |      Gets the value of impurity or its default value.\n |      \n |      .. versionadded:: 1.4.0\n |  \n |  setImpurity(self, value)\n |      Sets the value of :py:attr:&#96;impurity&#96;.\n |      \n |      .. versionadded:: 1.4.0\n |  \n |  ----------------------------------------------------------------------\n |  Data and other attributes inherited from TreeRegressorParams:\n |  \n |  impurity = Param(parent=&apos;undefined&apos;, name=&apos;impurity&apos;, doc=&apos;...(case-in...\n |  \n |  supportedImpurities = [&apos;variance&apos;]\n |  \n |  ----------------------------------------------------------------------\n |  Methods inherited from pyspark.ml.param.shared.HasCheckpointInterval:\n |  \n |  getCheckpointInterval(self)\n |      Gets the value of checkpointInterval or its default value.\n |  \n |  setCheckpointInterval(self, value)\n |      Sets the value of :py:attr:&#96;checkpointInterval&#96;.\n |  \n |  ----------------------------------------------------------------------\n |  Data and other attributes inherited from pyspark.ml.param.shared.HasCheckpointInterval:\n |  \n |  checkpointInterval = Param(parent=&apos;undefined&apos;, name=&apos;checkpointInterv....\n |  \n |  ----------------------------------------------------------------------\n |  Methods inherited from pyspark.ml.param.shared.HasSeed:\n |  \n |  getSeed(self)\n |      Gets the value of seed or its default value.\n |  \n |  setSeed(self, value)\n |      Sets the value of :py:attr:&#96;seed&#96;.\n |  \n |  ----------------------------------------------------------------------\n |  Data and other attributes inherited from pyspark.ml.param.shared.HasSeed:\n |  \n |  seed = Param(parent=&apos;undefined&apos;, name=&apos;seed&apos;, doc=&apos;random seed.&apos;)\n |  \n |  ----------------------------------------------------------------------\n |  Methods inherited from pyspark.ml.util.JavaMLWritable:\n |  \n |  write(self)\n |      Returns an MLWriter instance for this ML instance.\n |  \n |  ----------------------------------------------------------------------\n |  Methods inherited from pyspark.ml.util.MLWritable:\n |  \n |  save(self, path)\n |      Save this ML instance to the given path, a shortcut of &#96;write().save(path)&#96;.\n |  \n |  ----------------------------------------------------------------------\n |  Class methods inherited from pyspark.ml.util.JavaMLReadable:\n |  \n |  read(cls) from abc.ABCMeta\n |      Returns an MLReader instance for this class.\n |  \n |  ----------------------------------------------------------------------\n |  Class methods inherited from pyspark.ml.util.MLReadable:\n |  \n |  load(cls, path) from abc.ABCMeta\n |      Reads an ML instance from the input path, a shortcut of &#96;read().load(path)&#96;.\n |  \n |  ----------------------------------------------------------------------\n |  Methods inherited from pyspark.ml.param.shared.HasVarianceCol:\n |  \n |  getVarianceCol(self)\n |      Gets the value of varianceCol or its default value.\n |  \n |  setVarianceCol(self, value)\n |      Sets the value of :py:attr:&#96;varianceCol&#96;.\n |  \n |  ----------------------------------------------------------------------\n |  Data and other attributes inherited from pyspark.ml.param.shared.HasVarianceCol:\n |  \n |  varianceCol = Param(parent=&apos;undefined&apos;, name=&apos;varianceCol&apos;, do...e for...\n |  \n |  ----------------------------------------------------------------------\n |  Methods inherited from pyspark.ml.param.Params:\n |  \n |  copy(self, extra=None)\n |      Creates a copy of this instance with the same uid and some\n |      extra params. The default implementation creates a\n |      shallow copy using :py:func:&#96;copy.copy&#96;, and then copies the\n |      embedded and extra parameters over and returns the copy.\n |      Subclasses should override this method if the default approach\n |      is not sufficient.\n |      \n |      :param extra: Extra parameters to copy to the new instance\n |      :return: Copy of this instance\n |      \n |      .. versionadded:: 1.4.0\n |  \n |  explainParam(self, param)\n |      Explains a single param and returns its name, doc, and optional\n |      default value and user-supplied value in a string.\n |      \n |      .. versionadded:: 1.4.0\n |  \n |  explainParams(self)\n |      Returns the documentation of all params with their optionally\n |      default values and user-supplied values.\n |      \n |      .. versionadded:: 1.4.0\n |  \n |  extractParamMap(self, extra=None)\n |      Extracts the embedded default param values and user-supplied\n |      values, and then merges them with extra values from input into\n |      a flat param map, where the latter value is used if there exist\n |      conflicts, i.e., with ordering: default param values &lt;\n |      user-supplied values &lt; extra.\n |      \n |      :param extra: extra param values\n |      :return: merged param map\n |      \n |      .. versionadded:: 1.4.0\n |  \n |  getOrDefault(self, param)\n |      Gets the value of a param in the user-supplied param map or its\n |      default value. Raises an error if neither is set.\n |      \n |      .. versionadded:: 1.4.0\n |  \n |  getParam(self, paramName)\n |      Gets a param by its name.\n |      \n |      .. versionadded:: 1.4.0\n |  \n |  hasDefault(self, param)\n |      Checks whether a param has a default value.\n |      \n |      .. versionadded:: 1.4.0\n |  \n |  hasParam(self, paramName)\n |      Tests whether this instance contains a param with a given\n |      (string) name.\n |      \n |      .. versionadded:: 1.4.0\n |  \n |  isDefined(self, param)\n |      Checks whether a param is explicitly set by user or has\n |      a default value.\n |      \n |      .. versionadded:: 1.4.0\n |  \n |  isSet(self, param)\n |      Checks whether a param is explicitly set by user.\n |      \n |      .. versionadded:: 1.4.0\n |  \n |  ----------------------------------------------------------------------\n |  Data descriptors inherited from pyspark.ml.param.Params:\n |  \n |  params\n |      Returns all params ordered by name. The default implementation\n |      uses :py:func:&#96;dir&#96; to get all attributes of type\n |      :py:class:&#96;Param&#96;.\n |      \n |      .. versionadded:: 1.3.0\n |  \n |  ----------------------------------------------------------------------\n |  Methods inherited from pyspark.ml.util.Identifiable:\n |  \n |  __repr__(self)\n\n</div>","arguments":{},"addedWidgets":{},"removedWidgets":[]},"errorSummary":null,"error":null,"workflows":[],"startTime":1.481301790301E12,"submitTime":1.481301789856E12,"finishTime":1.481301790372E12,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":{"collapsed":false},"streamStates":{},"nuid":"72b2a1c1-62e7-4545-a4b9-78a3f62db64e"},{"version":"CommandV1","origId":465,"guid":"94c0883f-a93a-4183-b3c2-3e04d36074da","subtype":"command","commandType":"auto","position":32.0,"command":"%md The parameters that we used in our current model can be found via:","commandVersion":1,"state":"finished","results":{"type":"raw","data":"","arguments":{}},"errorSummary":null,"error":null,"workflows":[],"startTime":0.0,"submitTime":0.0,"finishTime":0.0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":{},"streamStates":{},"nuid":"aab55d76-5194-4b24-8526-575a06b309f1"},{"version":"CommandV1","origId":466,"guid":"4022d267-6ec0-4048-8d6b-6ebb67ece0ee","subtype":"command","commandType":"auto","position":33.0,"command":"print \"Decision Tree Model was fit using parameters: \", dt.explainParams()","commandVersion":1,"state":"finished","results":{"type":"html","data":"<div class=\"ansiout\">Decision Tree Model was fit using parameters:  cacheNodeIds: If false, the algorithm will pass trees to executors to match instances with nodes. If true, the algorithm will cache node IDs for each instance. Caching can speed up training of deeper trees. Users can set how often should the cache be checkpointed or disable it by setting checkpointInterval. (default: False)\ncheckpointInterval: set checkpoint interval (&gt;= 1) or disable checkpoint (-1). E.g. 10 means that the cache will get checkpointed every 10 iterations. (default: 10)\nfeaturesCol: features column name. (default: features, current: features)\nimpurity: Criterion used for information gain calculation (case-insensitive). Supported options: variance (default: variance)\nlabelCol: label column name. (default: label, current: price)\nmaxBins: Max number of bins for discretizing continuous features.  Must be &gt;=2 and &gt;= number of categories for any categorical feature. (default: 32)\nmaxDepth: Maximum depth of the tree. (&gt;= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes. (default: 5)\nmaxMemoryInMB: Maximum memory in MB allocated to histogram aggregation. If too small, then 1 node will be split per iteration, and its aggregates may exceed this size. (default: 256)\nminInfoGain: Minimum information gain for a split to be considered at a tree node. (default: 0.0)\nminInstancesPerNode: Minimum number of instances each child must have after split. If a split causes the left or right child to have fewer than minInstancesPerNode, the split will be discarded as invalid. Should be &gt;= 1. (default: 1)\npredictionCol: prediction column name. (default: prediction)\nseed: random seed. (default: -2808853809871465425)\nvarianceCol: column name for the biased sample variance of prediction. (undefined)\n</div>","arguments":{},"addedWidgets":{},"removedWidgets":[]},"errorSummary":null,"error":null,"workflows":[],"startTime":1.48130179433E12,"submitTime":1.481301793886E12,"finishTime":1.481301794368E12,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":{"collapsed":false},"streamStates":{},"nuid":"50667596-2f0e-40b0-9dcc-57012794a561"},{"version":"CommandV1","origId":467,"guid":"edbef789-ef32-4868-8416-b83c6c6d854e","subtype":"command","commandType":"auto","position":34.0,"command":"%md Particularly, our current tree has the max depth equals:","commandVersion":1,"state":"finished","results":{"type":"raw","data":"","arguments":{}},"errorSummary":null,"error":null,"workflows":[],"startTime":0.0,"submitTime":0.0,"finishTime":0.0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":{},"streamStates":{},"nuid":"d237e184-b547-47a8-8654-05169ce54088"},{"version":"CommandV1","origId":468,"guid":"51e2ab08-15e6-46d5-85f9-ebcaf321edce","subtype":"command","commandType":"auto","position":35.0,"command":"print \"Max Depth of the Regression Tree Model: \", dt.getMaxDepth()","commandVersion":1,"state":"finished","results":{"type":"html","data":"<div class=\"ansiout\">Max Depth of the Regression Tree Model:  5\n</div>","arguments":{},"addedWidgets":{},"removedWidgets":[]},"errorSummary":null,"error":null,"workflows":[],"startTime":1.481301798175E12,"submitTime":1.48130179773E12,"finishTime":1.481301798245E12,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":{"collapsed":false},"streamStates":{},"nuid":"c4db1f26-7a7d-46e8-84b2-2d85b558172b"},{"version":"CommandV1","origId":469,"guid":"8038a3fa-9f1c-4905-a35e-4f12739338df","subtype":"command","commandType":"auto","position":36.0,"command":"print \"Pipeline Stages: \", model.stages","commandVersion":1,"state":"finished","results":{"type":"html","data":"<div class=\"ansiout\">Pipeline Stages:  [StringIndexer_4faead2cae541a7752b3, OneHotEncoder_4325a7ea3b723f688912, StringIndexer_45ccad32dc91649b5c06, OneHotEncoder_47288a13118617cad590, StringIndexer_4f219600f4b5278ed3ff, OneHotEncoder_47eab594c8f6a9367d58, VectorAssembler_4191a43ea2cb981b4c8c, DecisionTreeRegressionModel (uid=DecisionTreeRegressor_4f0fb7c8801c7d21e101) of depth 5 with 63 nodes]\n</div>","arguments":{},"addedWidgets":{},"removedWidgets":[]},"errorSummary":null,"error":null,"workflows":[],"startTime":1.481301837979E12,"submitTime":1.481301837527E12,"finishTime":1.481301838017E12,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":{"collapsed":false},"streamStates":{},"nuid":"494d948d-2228-4e7b-8a63-aa266310bf7d"},{"version":"CommandV1","origId":470,"guid":"aa6b476c-075f-4c78-affb-18ed1ab56f88","subtype":"command","commandType":"auto","position":37.0,"command":"%md **Model selection via cross-validation**\n\nWe can perform cross-validation by using `CrossValidator` to select the best paramter set from a grid of parameters.","commandVersion":1,"state":"finished","results":{"type":"raw","data":"","arguments":{}},"errorSummary":null,"error":null,"workflows":[],"startTime":0.0,"submitTime":0.0,"finishTime":0.0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":{},"streamStates":{},"nuid":"a1ccc67e-b12b-4bdb-997c-2c166d95c9c7"},{"version":"CommandV1","origId":471,"guid":"0075c5ef-3ead-440b-9f66-d4aad69ef005","subtype":"command","commandType":"auto","position":38.0,"command":"from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n\nparamGrid = ParamGridBuilder()\\\n    .addGrid(dt.maxDepth, range(4, 15))\\\n    .build()\n\ncrossval = CrossValidator(estimator=pipeline,\n                          estimatorParamMaps=paramGrid,\n                          evaluator=evaluator,\n                          numFolds=5)\n\n# Run cross-validation, and choose the best set of parameters.\ncvModel = crossval.fit(training)\ncvPredict = cvModel.transform(test)","commandVersion":1,"state":"finished","results":{"type":"html","data":"<div class=\"ansiout\"></div>","arguments":{},"addedWidgets":{},"removedWidgets":[]},"errorSummary":null,"error":null,"workflows":[],"startTime":1.481302357688E12,"submitTime":1.481302357232E12,"finishTime":1.481302465932E12,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":{"collapsed":true},"streamStates":{},"nuid":"17909fd8-be26-4ddd-b1ae-fd1b64c31328"},{"version":"CommandV1","origId":472,"guid":"17134e7f-5404-47fc-a548-a77fc61e7e00","subtype":"command","commandType":"auto","position":39.0,"command":"cvPredict.printSchema()\ncvPredict.select(\"features\", \"price\",\"prediction\")\\\n    .show(10)","commandVersion":1,"state":"finished","results":{"type":"html","data":"<div class=\"ansiout\">root\n |-- carat: double (nullable = true)\n |-- cut: string (nullable = true)\n |-- color: string (nullable = true)\n |-- clarity: string (nullable = true)\n |-- depth: double (nullable = true)\n |-- table: double (nullable = true)\n |-- price: double (nullable = true)\n |-- x: double (nullable = true)\n |-- y: double (nullable = true)\n |-- z: double (nullable = true)\n |-- cutIndex: double (nullable = true)\n |-- cutclassVec: vector (nullable = true)\n |-- colorIndex: double (nullable = true)\n |-- colorclassVec: vector (nullable = true)\n |-- clarityIndex: double (nullable = true)\n |-- clarityclassVec: vector (nullable = true)\n |-- features: vector (nullable = true)\n |-- prediction: double (nullable = true)\n\n+--------------------+-----+------------------+\n|            features|price|        prediction|\n+--------------------+-----+------------------+\n|(23,[0,1,5,17,18,...|559.0| 576.3061224489796|\n|(23,[0,4,7,14,18,...|558.0|426.48837209302326|\n|(23,[0,2,6,14,18,...|558.0|484.54545454545456|\n|(23,[0,2,6,14,18,...|558.0|484.54545454545456|\n|(23,[0,2,7,14,18,...|558.0|484.54545454545456|\n|(23,[0,3,7,17,18,...|560.0| 549.5957446808511|\n|(23,[0,1,6,13,18,...|558.0| 435.7692307692308|\n|(23,[0,1,6,13,18,...|558.0| 435.7692307692308|\n|(23,[0,1,5,13,18,...|558.0| 435.7692307692308|\n|(23,[0,2,6,13,18,...|558.0|             435.0|\n+--------------------+-----+------------------+\nonly showing top 10 rows\n\n</div>","arguments":{},"addedWidgets":{},"removedWidgets":[]},"errorSummary":null,"error":null,"workflows":[],"startTime":1.481302537577E12,"submitTime":1.481302537112E12,"finishTime":1.481302537749E12,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":{"collapsed":false},"streamStates":{},"nuid":"0efc4484-e2df-4296-b4ff-386c2ffbbed0"},{"version":"CommandV1","origId":473,"guid":"39d6f42d-797c-4338-bb40-13288a463677","subtype":"command","commandType":"auto","position":40.0,"command":"%md Now the RMSE on test data is reduced to:","commandVersion":1,"state":"finished","results":{"type":"raw","data":"","arguments":{}},"errorSummary":null,"error":null,"workflows":[],"startTime":0.0,"submitTime":0.0,"finishTime":0.0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":{},"streamStates":{},"nuid":"3f9f4b4a-abee-4a7b-919a-7e4c9230d09d"},{"version":"CommandV1","origId":474,"guid":"d52469c3-7e4e-49e6-abfb-534a18a70710","subtype":"command","commandType":"auto","position":41.0,"command":"rmse = evaluator.evaluate(cvPredict)\nprint(\"Root Mean Squared Error (RMSE) on test data = %g\" % rmse)","commandVersion":1,"state":"finished","results":{"type":"html","data":"<div class=\"ansiout\">Root Mean Squared Error (RMSE) on test data = 804.456\n</div>","arguments":{},"addedWidgets":{},"removedWidgets":[]},"errorSummary":null,"error":null,"workflows":[],"startTime":1.481302550646E12,"submitTime":1.48130255018E12,"finishTime":1.481302550868E12,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":{"collapsed":false},"streamStates":{},"nuid":"f88d183f-fec4-4e19-92d9-3e6710302587"},{"version":"CommandV1","origId":475,"guid":"5d7a9288-0b13-4bc9-b3da-728f80c9dfb4","subtype":"command","commandType":"auto","position":42.0,"command":"cvModel.bestModel.stages","commandVersion":1,"state":"finished","results":{"type":"raw","data":"","arguments":{}},"errorSummary":null,"error":null,"workflows":[],"startTime":0.0,"submitTime":0.0,"finishTime":0.0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":{"collapsed":false},"streamStates":{},"nuid":"6f5979e0-51a5-474b-bee0-07d5a46e85c6"},{"version":"CommandV1","origId":476,"guid":"b3cb3cb1-ea0f-4046-a1e6-0d81b20ce744","subtype":"command","commandType":"auto","position":43.0,"command":"%md ### Saving and Loading Pipelines\n\nOften times it is worth it to save a model or a pipeline to disk for later use. We can:\n\n* use `.save(path)` to save this ML instance to the given path, and\n* use `.load(path)` to reads an ML instance from the input path.","commandVersion":1,"state":"finished","results":{"type":"raw","data":"","arguments":{}},"errorSummary":null,"error":null,"workflows":[],"startTime":0.0,"submitTime":0.0,"finishTime":0.0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":{},"streamStates":{},"nuid":"22378547-ade7-4432-b012-7e474ca79158"},{"version":"CommandV1","origId":477,"guid":"9b62c875-43e5-4c6f-86ea-8ed1e1596c74","subtype":"command","commandType":"auto","position":44.0,"command":"# To save a PipelineModel\ncvModel.bestModel.save(\"best_dt\")","commandVersion":1,"state":"finished","results":{"type":"raw","data":"","arguments":{}},"errorSummary":null,"error":null,"workflows":[],"startTime":0.0,"submitTime":0.0,"finishTime":0.0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":{"collapsed":false},"streamStates":{},"nuid":"075cf337-323e-462e-8b65-460de39624f9"},{"version":"CommandV1","origId":478,"guid":"7e6076ac-a54e-4309-977d-c05ff3bdcf8a","subtype":"command","commandType":"auto","position":45.0,"command":"from pyspark.ml import PipelineModel\n\n# To load a PipeLineModel\ncvModel_2 = PipelineModel.load(\"best_dt\")","commandVersion":1,"state":"finished","results":{"type":"raw","data":"","arguments":{}},"errorSummary":null,"error":null,"workflows":[],"startTime":0.0,"submitTime":0.0,"finishTime":0.0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":{"collapsed":false},"streamStates":{},"nuid":"cac40539-562e-49c7-9110-dd4b29497992"},{"version":"CommandV1","origId":479,"guid":"ab670535-7086-4dbf-8cb0-c02fd49e14d5","subtype":"command","commandType":"auto","position":46.0,"command":"%md ### Exercise 2\n\n2.1 Follow the same steps to train a `RandomForestRegressor` with the default parameters. What's your RMSE on test data?\n\n2.2 Use Cross-Validation to tune your parameters.","commandVersion":1,"state":"finished","results":{"type":"raw","data":"","arguments":{}},"errorSummary":null,"error":null,"workflows":[],"startTime":0.0,"submitTime":0.0,"finishTime":0.0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":{},"streamStates":{},"nuid":"12f5a657-7de6-4fd7-9ad8-dabf5a4c7d0e"},{"version":"CommandV1","origId":480,"guid":"4e09d653-8e63-4d5e-9f58-8546cdeb6723","subtype":"command","commandType":"auto","position":47.0,"command":"from pyspark.ml.regression import RandomForestRegressor\nfrom pyspark.ml import Pipeline\n\n# Train a DecisionTree model.\nrf = RandomForestRegressor(labelCol=\"price\", featuresCol=\"features\")\n\n# Chain indexer and tree in a Pipeline\npipeline = Pipeline(stages = stages + [assembler, rf])\n\n# Train model. This also runs the indexer.\nrfModel = pipeline.fit(training)","commandVersion":1,"state":"finished","results":{"type":"html","data":"<div class=\"ansiout\"></div>","arguments":{},"addedWidgets":{},"removedWidgets":[]},"errorSummary":null,"error":null,"workflows":[],"startTime":1.481303230448E12,"submitTime":1.481303229966E12,"finishTime":1.48130323276E12,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":{"collapsed":true},"streamStates":{},"nuid":"53d5c9ba-981e-4b5e-b42d-53cf06ff398d"},{"version":"CommandV1","origId":513,"guid":"483a7f61-ec68-45f8-aba7-455afcdc4448","subtype":"command","commandType":"auto","position":47.5,"command":"paramGrid = ParamGridBuilder()\\\n    .addGrid(rf.maxDepth, range(4, 15))\\\n    .build()\n\ncrossval = CrossValidator(estimator=pipeline,\n                          estimatorParamMaps=paramGrid,\n                          evaluator=evaluator,\n                          numFolds=5)\n\n# Run cross-validation, and choose the best set of parameters.\ncvModel = crossval.fit(training)\ncvPredict = cvModel.transform(test)","commandVersion":0,"state":"finished","results":{"type":"html","data":"<div class=\"ansiout\"></div>","arguments":{},"addedWidgets":{},"removedWidgets":[]},"errorSummary":null,"error":null,"workflows":[],"startTime":1.481303467945E12,"submitTime":1.481303467464E12,"finishTime":1.481304098194E12,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"25c4657c-0edb-4be3-8b6c-7f97049dcb71"},{"version":"CommandV1","origId":517,"guid":"5d4ef87d-91b4-4012-b041-adcf7617958c","subtype":"command","commandType":"auto","position":47.75,"command":"rmse = evaluator.evaluate(cvPredict)\nprint(\"Root Mean Squared Error (RMSE) on test data = %g\" % rmse)","commandVersion":0,"state":"finished","results":{"type":"html","data":"<div class=\"ansiout\">Root Mean Squared Error (RMSE) on test data = 760.123\n</div>","arguments":{},"addedWidgets":{},"removedWidgets":[]},"errorSummary":null,"error":null,"workflows":[],"startTime":1.481304460215E12,"submitTime":1.481304459707E12,"finishTime":1.481304461188E12,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"fd6f0f25-ace9-4f6f-a40e-fb6540e47a70"},{"version":"CommandV1","origId":481,"guid":"5ccfe9c8-ed76-44bf-b84e-32d8364587f0","subtype":"command","commandType":"auto","position":48.0,"command":"# Make predictions.\nrfPredictions = rfModel.transform(test)\n\nrfPredictions.printSchema()\nrfPredictions.select(\"features\", \"price\", \"prediction\")\\\n    .show(10)","commandVersion":1,"state":"finished","results":{"type":"raw","data":"","arguments":{}},"errorSummary":null,"error":null,"workflows":[],"startTime":0.0,"submitTime":0.0,"finishTime":0.0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":{"collapsed":false},"streamStates":{},"nuid":"2407fd69-e407-48cd-a6a5-8d16a54f8890"},{"version":"CommandV1","origId":482,"guid":"1de5e8ff-8e04-4a18-a401-cce4d4b6380d","subtype":"command","commandType":"auto","position":49.0,"command":"# Select (prediction, true label) and compute test error\nrfRmse = evaluator.evaluate(rfPredictions)\nprint(\"Root Mean Squared Error (RMSE) on test data = %g\" % rfRmse)","commandVersion":1,"state":"finished","results":{"type":"raw","data":"","arguments":{}},"errorSummary":null,"error":null,"workflows":[],"startTime":0.0,"submitTime":0.0,"finishTime":0.0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":{"collapsed":false},"streamStates":{},"nuid":"dcb8d1db-67a6-4515-8406-944da34392f6"},{"version":"CommandV1","origId":483,"guid":"3f8f1fb4-e5dc-4969-be3b-5915df6fb37b","subtype":"command","commandType":"auto","position":50.0,"command":"print rfModel.stages","commandVersion":1,"state":"finished","results":{"type":"raw","data":"","arguments":{}},"errorSummary":null,"error":null,"workflows":[],"startTime":0.0,"submitTime":0.0,"finishTime":0.0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":{"collapsed":false},"streamStates":{},"nuid":"bbc1d0a5-6501-4e9a-b2b0-ad8f804cda87"},{"version":"CommandV1","origId":484,"guid":"58949064-6dd8-4809-89c5-ce6f398bf516","subtype":"command","commandType":"auto","position":51.0,"command":"print rf.explainParams()","commandVersion":1,"state":"finished","results":{"type":"raw","data":"","arguments":{}},"errorSummary":null,"error":null,"workflows":[],"startTime":0.0,"submitTime":0.0,"finishTime":0.0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":{"collapsed":false},"streamStates":{},"nuid":"e0a1ba7e-1657-498f-b536-d593a533e57d"},{"version":"CommandV1","origId":485,"guid":"772f4e97-fedd-4e27-b35d-bdc1b785e6f2","subtype":"command","commandType":"auto","position":52.0,"command":"from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n\nparamGrid = ParamGridBuilder()\\\n    .addGrid(rf.maxDepth, range(3,7))\\\n    .addGrid(rf.numTrees, [20, 30, 40])\\\n    .addGrid(rf.subsamplingRate, [.6, .8, 1.0])\\\n    .build()\n\ncrossval = CrossValidator(estimator=rfPipeline,\n                          estimatorParamMaps=paramGrid,\n                          evaluator=evaluator,\n                          numFolds=5)\n\n# Run cross-validation, and choose the best set of parameters.\ncvModel = crossval.fit(training)\ncvPredict = cvModel.transform(test)\n\n# \nrmse = evaluator.evaluate(cvPredict)\nprint(\"Root Mean Squared Error (RMSE) on test data = %g\" % rmse)","commandVersion":1,"state":"error","results":null,"errorSummary":"<span class=\"ansired\">NameError</span>: name &apos;rf&apos; is not defined","error":"<div class=\"ansiout\"><span class=\"ansired\">---------------------------------------------------------------------------</span>\n<span class=\"ansired\">NameError</span>                                 Traceback (most recent call last)\n<span class=\"ansigreen\">&lt;ipython-input-3-e4f486496b7e&gt;</span> in <span class=\"ansicyan\">&lt;module&gt;</span><span class=\"ansiblue\">()</span>\n<span class=\"ansigreen\">      1</span> <span class=\"ansigreen\">from</span> pyspark<span class=\"ansiyellow\">.</span>ml<span class=\"ansiyellow\">.</span>tuning <span class=\"ansigreen\">import</span> CrossValidator<span class=\"ansiyellow\">,</span> ParamGridBuilder<span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">      2</span> <span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">----&gt; 3</span><span class=\"ansiyellow\"> </span>paramGrid <span class=\"ansiyellow\">=</span> ParamGridBuilder<span class=\"ansiyellow\">(</span><span class=\"ansiyellow\">)</span>    <span class=\"ansiyellow\">.</span>addGrid<span class=\"ansiyellow\">(</span>rf<span class=\"ansiyellow\">.</span>maxDepth<span class=\"ansiyellow\">,</span> range<span class=\"ansiyellow\">(</span><span class=\"ansicyan\">3</span><span class=\"ansiyellow\">,</span><span class=\"ansicyan\">7</span><span class=\"ansiyellow\">)</span><span class=\"ansiyellow\">)</span>    <span class=\"ansiyellow\">.</span>addGrid<span class=\"ansiyellow\">(</span>rf<span class=\"ansiyellow\">.</span>numTrees<span class=\"ansiyellow\">,</span> <span class=\"ansiyellow\">[</span><span class=\"ansicyan\">20</span><span class=\"ansiyellow\">,</span> <span class=\"ansicyan\">30</span><span class=\"ansiyellow\">,</span> <span class=\"ansicyan\">40</span><span class=\"ansiyellow\">]</span><span class=\"ansiyellow\">)</span>    <span class=\"ansiyellow\">.</span>addGrid<span class=\"ansiyellow\">(</span>rf<span class=\"ansiyellow\">.</span>subsamplingRate<span class=\"ansiyellow\">,</span> <span class=\"ansiyellow\">[</span><span class=\"ansicyan\">.6</span><span class=\"ansiyellow\">,</span> <span class=\"ansicyan\">.8</span><span class=\"ansiyellow\">,</span> <span class=\"ansicyan\">1.0</span><span class=\"ansiyellow\">]</span><span class=\"ansiyellow\">)</span>    <span class=\"ansiyellow\">.</span>build<span class=\"ansiyellow\">(</span><span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">      4</span> <span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">      5</span> crossval = CrossValidator(estimator=rfPipeline,\n\n<span class=\"ansired\">NameError</span>: name &apos;rf&apos; is not defined\n</div>","workflows":[],"startTime":1.481512265813E12,"submitTime":1.481512265813E12,"finishTime":1.481512266071E12,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":{"collapsed":false},"streamStates":{},"nuid":"7d3ab7b5-93d5-422a-a9b3-b985f7515366"},{"version":"CommandV1","origId":486,"guid":"dc8c2671-739f-43e7-9a59-ac19c2bcc849","subtype":"command","commandType":"auto","position":53.0,"command":"%md ## ML Pipeline Example: Movie Recommendations\n\n*Collaborative filtering* is a method of making automatic predictions (filtering) about the interests of a user by collecting preferences or taste information from many users (collaborating). The underlying assumption of the collaborative filtering approach is that if a person A has the same opinion as a person B on an issue, A is more likely to have B's opinion on a different issue x than to have the opinion on x of a person chosen randomly.\n\nThe image below (from [Wikipedia][collab]) shows an example of predicting of the user's rating using collaborative filtering. At first, people rate different items (like videos, images, games). After that, the system is making predictions about a user's rating for an item, which the user has not rated yet. These predictions are built upon the existing ratings of other users, who have similar ratings with the active user. For instance, in the image below the system has made a prediction, that the active user will not like the video.\n![collaborative filtering](https://courses.edx.org/c4x/BerkeleyX/CS100.1x/asset/Collaborative_filtering.gif)\n \n[mllib]: https://spark.apache.org/mllib/\n[collab]: https://en.wikipedia.org/?title=Collaborative_filtering\n[collab2]: http://recommender-systems.org/collaborative-filtering/\n\nFor movie recommendations, we start with a matrix whose entries are movie ratings by users (shown in red in the diagram below).  Each column represents a user (shown in green) and each row represents a particular movie (shown in blue).\n \nSince not all users have rated all movies, we do not know all of the entries in this matrix, which is precisely why we need collaborative filtering.  For each user, we have ratings for only a subset of the movies.  With collaborative filtering, the idea is to approximate the ratings matrix by factorizing it as the product of two matrices: one that describes properties of each user (shown in green), and one that describes properties of each movie (shown in blue).\n \n![factorization](http://spark-mooc.github.io/web-assets/images/matrix_factorization.png)\nWe want to select these two matrices such that the error for the users/movie pairs where we know the correct ratings is minimized.  The [Alternating Least Squares][als] algorithm does this by first randomly filling the users matrix with values and then optimizing the value of the movies such that the error is minimized.  Then, it holds the movies matrix constrant and optimizes the value of the user's matrix.  This alternation between which matrix to optimize is the reason for the \"alternating\" in the name.\n \nThis optimization is what's being shown on the right in the image above.  Given a fixed set of user factors (i.e., values in the users matrix), we use the known ratings to find the best values for the movie factors using the optimization written at the bottom of the figure.  Then we \"alternate\" and pick the best user factors given fixed movie factors.\n\n### Loading DataFrame","commandVersion":1,"state":"finished","results":{"type":"raw","data":"","arguments":{}},"errorSummary":null,"error":null,"workflows":[],"startTime":0.0,"submitTime":0.0,"finishTime":0.0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":{"collapsed":true},"streamStates":{},"nuid":"b672701b-137d-4119-a639-0ed02c9f386e"},{"version":"CommandV1","origId":487,"guid":"cd1b8676-2ab9-4b05-878e-e7d0bcb77f41","subtype":"command","commandType":"auto","position":54.0,"command":"from pyspark.sql.types import *\n\nratingSchema = StructType([StructField(\"userId\", IntegerType(), True),\n                           StructField(\"movieId\", IntegerType(), True),\n                           StructField(\"rating\", IntegerType(), True),\n                           StructField(\"timestamp\", IntegerType(), True)])\nratingPath = os.path.join(dataPath, \"ml-100k/u.data\")\n\nratings = spark.read.csv(path=ratingPath, sep=u\"\\t\", schema=ratingSchema)","commandVersion":1,"state":"finished","results":{"type":"html","data":"<div class=\"ansiout\"></div>","arguments":{},"addedWidgets":{},"removedWidgets":[]},"errorSummary":null,"error":null,"workflows":[],"startTime":1.481512302391E12,"submitTime":1.481512303515E12,"finishTime":1.481512302612E12,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":{"collapsed":false},"streamStates":{},"nuid":"338cf5b9-7123-4361-b9d0-3c92268a6086"},{"version":"CommandV1","origId":488,"guid":"9685ca05-c0a1-437d-998b-6b951df3d1e1","subtype":"command","commandType":"auto","position":55.0,"command":"ratings.show(3)","commandVersion":1,"state":"finished","results":{"type":"html","data":"<div class=\"ansiout\">+------+-------+------+---------+\n|userId|movieId|rating|timestamp|\n+------+-------+------+---------+\n|   196|    242|     3|881250949|\n|   186|    302|     3|891717742|\n|    22|    377|     1|878887116|\n+------+-------+------+---------+\nonly showing top 3 rows\n\n</div>","arguments":{},"addedWidgets":{},"removedWidgets":[]},"errorSummary":null,"error":null,"workflows":[],"startTime":1.481512303928E12,"submitTime":1.481512305052E12,"finishTime":1.4815123045E12,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":{"collapsed":false},"streamStates":{},"nuid":"3ec57ed3-6122-47bf-885e-bc018fc3503a"},{"version":"CommandV1","origId":489,"guid":"3fe4e094-cc81-4345-9081-e366ea08c24b","subtype":"command","commandType":"auto","position":56.0,"command":"%md ## 2. Collaborative Filtering\n\n`spark.ml` currently supports model-based collaborative filtering, in which users and products are described by a small set of latent factors that can be used to predict missing entries. `spark.ml` uses the alternating least squares (ALS) algorithm to learn these latent factors.","commandVersion":1,"state":"finished","results":{"type":"raw","data":"","arguments":{}},"errorSummary":null,"error":null,"workflows":[],"startTime":0.0,"submitTime":0.0,"finishTime":0.0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":{},"streamStates":{},"nuid":"5ab1d7d8-4dd3-4a08-a2bc-87a9bf390c66"},{"version":"CommandV1","origId":490,"guid":"8c89f60f-bf76-420d-8f13-659b4e42c102","subtype":"command","commandType":"auto","position":57.0,"command":"from pyspark.ml.recommendation import ALS\nfrom pyspark.ml.evaluation import RegressionEvaluator\n\ntraining, test = ratings.randomSplit([0.8, 0.2])\n\nals = ALS(maxIter=50, regParam=0.01, \n          userCol=\"userId\", itemCol=\"movieId\", ratingCol=\"rating\")\n\nmodel = als.fit(training)\n\n# Evaluate the model by computing the RMSE on the test data\npredictions = model.transform(test).dropna(how='any')\n\nevaluator = RegressionEvaluator(metricName=\"rmse\", \n                                labelCol=\"rating\",\n                                predictionCol=\"prediction\")\nrmse = evaluator.evaluate(predictions)\nprint \"RMSE = \" + str(rmse)","commandVersion":1,"state":"finished","results":{"type":"html","data":"<div class=\"ansiout\">RMSE = 1.10014664785\n</div>","arguments":{},"addedWidgets":{},"removedWidgets":[]},"errorSummary":"<span class=\"ansired\">NameError</span>: name &apos;ratings&apos; is not defined","error":"<div class=\"ansiout\"><span class=\"ansired\">---------------------------------------------------------------------------</span>\n<span class=\"ansired\">NameError</span>                                 Traceback (most recent call last)\n<span class=\"ansigreen\">&lt;ipython-input-1-56f26e5f5a39&gt;</span> in <span class=\"ansicyan\">&lt;module&gt;</span><span class=\"ansiblue\">()</span>\n<span class=\"ansigreen\">      2</span> <span class=\"ansigreen\">from</span> pyspark<span class=\"ansiyellow\">.</span>ml<span class=\"ansiyellow\">.</span>evaluation <span class=\"ansigreen\">import</span> RegressionEvaluator<span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">      3</span> <span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">----&gt; 4</span><span class=\"ansiyellow\"> </span>training<span class=\"ansiyellow\">,</span> test <span class=\"ansiyellow\">=</span> ratings<span class=\"ansiyellow\">.</span>randomSplit<span class=\"ansiyellow\">(</span><span class=\"ansiyellow\">[</span><span class=\"ansicyan\">0.8</span><span class=\"ansiyellow\">,</span> <span class=\"ansicyan\">0.2</span><span class=\"ansiyellow\">]</span><span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">      5</span> <span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">      6</span> als = ALS(maxIter=50, regParam=0.01, \n\n<span class=\"ansired\">NameError</span>: name &apos;ratings&apos; is not defined\n</div>","workflows":[],"startTime":1.481512307057E12,"submitTime":1.481512308179E12,"finishTime":1.481512320121E12,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":{"collapsed":false},"streamStates":{},"nuid":"13a53a56-1fda-47aa-a4a8-65548b044637"},{"version":"CommandV1","origId":491,"guid":"cfcfe9a9-6c72-4371-bb5e-c763c942eb3e","subtype":"command","commandType":"auto","position":58.0,"command":"# Your code goes here\n\n# We now treat the Pipeline as an Estimator, wrapping it in a CrossValidator instance.\n# This will allow us to jointly choose parameters for all Pipeline stages.\n# A CrossValidator requires an Estimator, a set of Estimator ParamMaps, and an Evaluator.\n# We use a ParamGridBuilder to construct a grid of parameters to search over.\nparamGrid = (ParamGridBuilder()\n             .addGrid(als.regParam, [0.3, 0.1, 0.03])\n             .addGrid(als.rank, [15, 20, 25])\n             .build())\n\ncrossval = CrossValidator(estimator=als,\n                          estimatorParamMaps=paramGrid,\n                          evaluator=RegressionEvaluator(metricName=\"rmse\", \n                                                        labelCol=\"rating\",\n                                                        predictionCol=\"prediction\"),\n                          numFolds=5)  # use 3+ folds in practice\n\n# Run cross-validation, and choose the best set of parameters.\ncvModel = crossval.fit(training)\n\n# Make predictions on test documents. cvModel uses the best model found (lrModel).\nprediction = cvModel.transform(test).dropna(how='any')\nevaluator = RegressionEvaluator(metricName=\"rmse\", \n                                labelCol=\"rating\",\n                                predictionCol=\"prediction\")\nrmse = evaluator.evaluate(predictions)\nprint \"RMSE = \" + str(rmse)","commandVersion":1,"state":"finished","results":{"type":"html","data":"<div class=\"ansiout\">RMSE = 1.10014664785\n</div>","arguments":{},"addedWidgets":{},"removedWidgets":[]},"errorSummary":"<span class=\"ansired\">NameError</span>: name &apos;ParamGridBuilder&apos; is not defined","error":"<div class=\"ansiout\"><span class=\"ansired\">---------------------------------------------------------------------------</span>\n<span class=\"ansired\">NameError</span>                                 Traceback (most recent call last)\n<span class=\"ansigreen\">&lt;ipython-input-2-47e02d591212&gt;</span> in <span class=\"ansicyan\">&lt;module&gt;</span><span class=\"ansiblue\">()</span>\n<span class=\"ansigreen\">      5</span> <span class=\"ansired\"># A CrossValidator requires an Estimator, a set of Estimator ParamMaps, and an Evaluator.</span><span class=\"ansiyellow\"></span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">      6</span> <span class=\"ansired\"># We use a ParamGridBuilder to construct a grid of parameters to search over.</span><span class=\"ansiyellow\"></span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">----&gt; 7</span><span class=\"ansiyellow\"> paramGrid = (ParamGridBuilder()\n</span><span class=\"ansigreen\">      8</span>              <span class=\"ansiyellow\">.</span>addGrid<span class=\"ansiyellow\">(</span>als<span class=\"ansiyellow\">.</span>regParam<span class=\"ansiyellow\">,</span> <span class=\"ansiyellow\">[</span><span class=\"ansicyan\">0.3</span><span class=\"ansiyellow\">,</span> <span class=\"ansicyan\">0.1</span><span class=\"ansiyellow\">,</span> <span class=\"ansicyan\">0.03</span><span class=\"ansiyellow\">]</span><span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">      9</span>              <span class=\"ansiyellow\">.</span>addGrid<span class=\"ansiyellow\">(</span>als<span class=\"ansiyellow\">.</span>rank<span class=\"ansiyellow\">,</span> <span class=\"ansiyellow\">[</span><span class=\"ansicyan\">15</span><span class=\"ansiyellow\">,</span> <span class=\"ansicyan\">20</span><span class=\"ansiyellow\">,</span> <span class=\"ansicyan\">25</span><span class=\"ansiyellow\">]</span><span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n\n<span class=\"ansired\">NameError</span>: name &apos;ParamGridBuilder&apos; is not defined\n</div>","workflows":[],"startTime":1.481512332089E12,"submitTime":1.481512333208E12,"finishTime":1.481512841398E12,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":{"collapsed":true},"streamStates":{},"nuid":"b9ac6191-f302-42bd-a71c-8d1eadb5641d"},{"version":"CommandV1","origId":492,"guid":"089c01e4-7200-446e-9459-5d299a4b3343","subtype":"command","commandType":"auto","position":59.0,"command":"predictionAndLabels = sc.parallelize([\n([1, 6, 2, 7, 8, 3, 9, 10, 4, 5], [1, 2, 3, 4, 5]),\n([4, 1, 5, 6, 2, 7, 3, 8, 9, 10], [1, 2, 3]),\n([1, 2, 3, 4, 5], [])])","commandVersion":1,"state":"finished","results":{"type":"html","data":"<div class=\"ansiout\"></div>","arguments":{},"addedWidgets":{},"removedWidgets":[]},"errorSummary":null,"error":null,"workflows":[],"startTime":1.481305204689E12,"submitTime":1.481305204152E12,"finishTime":1.481305204727E12,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":{},"streamStates":{},"nuid":"8352f473-7a1b-4c22-85af-b9bee91ce447"},{"version":"CommandV1","origId":528,"guid":"8f86f3f2-7191-4126-a57f-09df3cd63bbe","subtype":"command","commandType":"auto","position":60.0,"command":"from pyspark.mllib.evaluation import RankingMetrics\nmetrics = RankingMetrics(predictionAndLabels)","commandVersion":0,"state":"finished","results":{"type":"html","data":"<div class=\"ansiout\"></div>","arguments":{},"addedWidgets":{},"removedWidgets":[]},"errorSummary":"<span class=\"ansired\">NameError</span>: name &apos;RankingMetrics&apos; is not defined","error":"<div class=\"ansiout\"><span class=\"ansired\">---------------------------------------------------------------------------</span>\n<span class=\"ansired\">NameError</span>                                 Traceback (most recent call last)\n<span class=\"ansigreen\">&lt;ipython-input-43-c72c1c4feeaa&gt;</span> in <span class=\"ansicyan\">&lt;module&gt;</span><span class=\"ansiblue\">()</span>\n<span class=\"ansigreen\">----&gt; 1</span><span class=\"ansiyellow\"> </span>metrics <span class=\"ansiyellow\">=</span> RankingMetrics<span class=\"ansiyellow\">(</span>predictionAndLabels<span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n\n<span class=\"ansired\">NameError</span>: name &apos;RankingMetrics&apos; is not defined\n</div>","workflows":[],"startTime":1.481305239176E12,"submitTime":1.481305238533E12,"finishTime":1.481305239398E12,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"99b7c3c3-af54-4a06-a5ca-534851ebb131"},{"version":"CommandV1","origId":529,"guid":"b57df81f-24ed-4585-a41a-53eba8ef882e","subtype":"command","commandType":"auto","position":61.0,"command":"print metrics.meanAveragePrecision","commandVersion":0,"state":"finished","results":{"type":"html","data":"<div class=\"ansiout\">0.355026455026\n</div>","arguments":{},"addedWidgets":{},"removedWidgets":[]},"errorSummary":null,"error":null,"workflows":[],"startTime":1.481305269287E12,"submitTime":1.481305267967E12,"finishTime":1.481305269459E12,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"1e925449-2da8-431d-9e86-5af0a1d0686a"}],"dashboards":[],"guid":"cbc552ef-49d4-4051-b50f-eb9c95a122fd","globalVars":{},"iPythonMetadata":{"nbformat":4.0,"IPythonMetadata":{"kernelspec":{"display_name":"Python 2","language":"python","name":"python2"},"language_info":{"mimetype":"text/x-python","name":"python","pygments_lexer":"ipython2","codemirror_mode":{"name":"ipython","version":2.0},"version":"2.7.11","nbconvert_exporter":"python","file_extension":".py"},"name":"spark_MLlib","notebookId":3.123782145633077E15}},"inputWidgets":{}};</script>
<script
 src="https://databricks-prod-cloudfront.cloud.databricks.com/static/e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855/js/notebook-main.js"
 onerror="window.mainJsLoadError = true;"></script>
<script>var tableOfContentsCell = {"version":"CommandV1","origId":0,"guid":"35152fc7-adff-4644-bc81-a096b62e9303","subtype":"command","commandType":"auto","position":0.0,"command":"%md [&lsaquo; Back to Table of Contents](../index.html)","commandVersion":1,"state":"finished","results":{"type":"raw","data":"","arguments":{}},"errorSummary":null,"error":null,"workflows":[],"startTime":0.0,"submitTime":0.0,"finishTime":0.0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{}};</script>
</head>
<body>
  <script>
if (window.mainJsLoadError) {
  var u = 'https://databricks-prod-cloudfront.cloud.databricks.com/static/e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855/js/notebook-main.js';
  var b = document.getElementsByTagName('body')[0];
  var c = document.createElement('div');
  c.innerHTML = ('<h1>Network Error</h1>' +
    '<p><b>Please check your network connection and try again.</b></p>' +
    '<p>Could not load a required resource: ' + u + '</p>');
  c.style.margin = '30px';
  c.style.padding = '20px 50px';
  c.style.backgroundColor = '#f5f5f5';
  c.style.borderRadius = '5px';
  b.appendChild(c);
}
</script>
</body>
</html>