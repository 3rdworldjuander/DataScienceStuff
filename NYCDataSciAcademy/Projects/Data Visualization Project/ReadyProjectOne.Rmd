---
title: "ReadyProjectOne"
author: "Oamar Gianan"
date: "October 10, 2016"
output: html_document
---

***

# Twitter Network Exploration
### A visual exploration of tweets on NASDAQ 100 stocks

***

##About the Dataset

* Source:
       + [Follow The Hashtag](http://followthehashtag.com/datasets/nasdaq-100-companies-free-twitter-dataset/)
* Measured time:
       + From 2016 March 28th to 2016 June 15th
       + 79 days
* Format: 
       + 6 Excel files per company
* Twitter Stream: 
       + Included in "Dashboad" file in Sheet named Stream
       + Retweets are included in this datasets
* Size: 
       + 178 Mb (compressed)

***

## Questions

As a network analysis, I wanted to find out the following:

* Who are the top influentials?
* Who is the most influential user?
* Which stocks are the most influential users talking about?
* Which events caused the most chatter?

* Is there a corellation between stock movement and number of tweets? Which stock causes more people to tweet?
* Is there early chatter before significant price movements?

***

## Preparing the Dataset

* Dataset was organized per company
* 103 companies with six excel files each
       + Discovery Communications has two listings: $DISCA, $DISCK
       + Alphabet, Inc. (Google) has two listings: $GOOGL, $GOOG
       + Liberty Global has two listings: $LBTYA, $LBTYK
* Twitter stream was listed in the second sheet in one of the excel files

###BASH Scripting

Excel files were in nested zip files.
<EXPOUND MORE>

This is the bash script to automate unzipping and organize all excel files with the tweet stream into one folder

```{bash unzip, eval=FALSE}
#/bin/sh

mkdir all/
for file in *.zip  
	do
	unzip "$file" -d all
done
	
cd all/
mkdir sheets/
for zips in *.zip
	do 
	unzip "$zips" -d sheets/
done

cd sheets/
mkdir dashboards/
for sheets in export_dash*
	do
	mv "$sheets" dashboards/
done
```


### Converting xlsx to csv

Found python utility which easily converts xlsx files to csv. Supports conversion of xlsx files with multiple sheets. Can be automated using bash scripting also.

This is the bash script to convert multiple xlsx files to csvs.

```{bash xlsx2csv, eval=FALSE}
#/bin/sh
mkdir csv/
for dash in expo*
	do
	xlsx2csv -s 2 "$dash" csv/"${dash%.*}".csv
done
```

###Preparing the Raw Stream Dataframe 

Initial library calls.
<DESCRIBE LIBRARIES USED>

```{r load libraries, echo=TRUE, message=TRUE, warning=TRUE}

library(readr)
library(dplyr)
library(ggplot2)
library(data.table) # for frank function
library(knitr)
library(plyr)
library(VennDiagram)
library(corrplot)
library(wordcloud)
library(lubridate)
library(stringr)
library(tidyr)
library(igraph)


options(scipen = 100)
#library(network)
#library(sna)
#library(qdap)
#library(tm)

```

### Loading multiple csv into a single dataframe.

```{r read cvs, eval=FALSE, message=FALSE, warning=FALSE, include=FALSE}

csvs <- list.files(path = 'csv/', pattern = ".csv")
csvs <- paste('csv/', csvs, sep = '')
length(csvs)
stream <- do.call("rbind", lapply(csvs, read_csv))

#Discard duplicate tweets

stream <- stream %>% filter(duplicated(`Tweet Id`) == FALSE) 

#Fix timestamp
#EDIT TO ADD tz
stream$Timestamp <- as.POSIXct((stream$Date + seconds_to_period(stream$Hour)), tz = "America/New_York")

#Cleaning NAs

stream <- stream %>%
      mutate(Followers = ifelse(is.na(Followers),0,Followers))

stream <- stream %>%
      mutate(RTs = ifelse(is.na(RTs),0,RTs))

```

### Saving the object for later use.

```{r save RDS, eval=FALSE, include=FALSE}

saveRDS(stream, file = 'allStream.RDS')

```

readRDS is a temporary code chink for troubleshooting RMarkdown. REMOVE WHEN DONE

```{r read RDS, include=FALSE}

#stream <- readRDS('allStream.RDS')

stream <- readRDS('caStream')

```

***

## The Dataset

### Number of unique users (based on Nickname)

```{r unique users}

length(unique(stream$Nickname))
NicknameList <- as.data.frame(unique(stream$Nickname))
names(NicknameList) <- 'Nickname'

```

### Number of unique tweets (based on Tweet Id, RTs recieve a unique Tweet ID too)

```{r unique tweets, echo=TRUE, eval = FALSE}

length(unique(stream$`Tweet Id`))

```

### The Most Talked About Stock

Which stock are the users talking about the most?

```{r topSymbols, eval = FALSE}

allSymbols  <- stream %>% select(Symbols)

```

```{r dfSymbols To Vec, eval = FALSE}

allSymbols <- toupper(unlist(strsplit(allSymbols$Symbols, ',')))

```

Tabulate occurences and convert to data frame

```{r Tabulate Symbols, eval = FALSE}

SymFreq <- as.data.frame(table(allSymbols), stringsAsFactors = FALSE)
names(SymFreq) <- c('Symbol', 'Freq')

```

```{r wordcloud, eval = FALSE}
png(filename = "wordcloud.png")
wordcloud(
       words = SymFreq$Symbol, 
       freq = SymFreq$Freq, 
       scale=c(4,.5),
       min.freq = 3, 
       max.words=100, 
       random.order=FALSE, 
       rot.per=0.35, 
       colors=brewer.pal(8, "Dark2")
       )
dev.off()
```


### Significant Events

When was there the most tweets?

To get a visual representation of the frequency of tweets, ggplot was used to display the frequency of tweets over the duration of the stream.

```{r events, echo=TRUE, eval = FALSE}

#for zooming into dates on durationDist
#zoom <- as_date(c("2016-04-25","2016-05-01"))
zoom <- NULL

durationDist = ggplot(
                     stream, 
                     aes(Date)
                     ) + 
              geom_density(
                     aes(fill = `Is a RT`), 
                     alpha = 0.5
                     ) +
              scale_fill_discrete(
                     guide = 'none'
                     ) +
              scale_x_date(
                     name = "2016", 
                     date_labels = "%b %d", 
                     date_breaks = "2 weeks", 
                     date_minor_breaks = "1 week", 
                     limits = zoom
                     ) +
              xlab(
                     'All tweets'
                     )
png(filename = "freqStream.png")
       plot(durationDist)
dev.off()
```

Verifying by code, we get the date with the most tweets.

```{r day of max tweet, eval = FALSE}

twperday <- stream %>% group_by(.,Date) %>% dplyr::summarise(.,Tweets=n())

maxday <- twperday[which.max(twperday$Tweets), ]

```

<!-- At what time during `r month(maxday[[1]], label = T)` `r day(maxday[[1]])` did users tweet? -->

<!-- A histogram of `r month(maxday[[1]], label = T)` `r day(maxday[[1]])` was  plotted to show at which time of the day the users tweet the most. -->

```{r day of event, eval = FALSE}

event <- subset(stream, month(stream$Timestamp) == month(maxday[[1]]) & 
                     day(stream$Timestamp) == day(maxday[[1]]))

timeofdayDist = ggplot(
                     event, 
                     aes(Timestamp)
                     ) + 
                     geom_density(
                            aes(fill = `Is a RT`), 
                            alpha = 0.5
                            ) +
                     scale_fill_discrete(guide = 'none') +
                     xlab('All tweets')
png(filename = "freqMaxday.png")
       plot(timeofdayDist)
dev.off()

```

Verifying by code

```{r time of day of max tweet, eval = FALSE}
#how to group into chunks of 15 minutes. or variable minutes?
#<check out cut.Date to factorize a continuous variable like time/date>

timeofday <- event %>% group_by(.,hour(event$Timestamp)) %>% dplyr::summarise(.,Tweets=n())

timeofday[which.max(timeofday$Tweets), ]

```

***

## Measure of Influence

<CITATION: Measuring User Influence in Twitter: The Million Follower Fallacy, Cha, Haddadi, Benevenuto, Gummadi. 2010>  

Three measures of influence:

1.  Indegree influence.  
    + The number of people who follow a user.
    + Directly indicates the audience size of the user.
2.  Retweet influence.  
    + The number of times others "forward" a user's tweet.
    + Represents the ability of the user to create content with pass-along value.
3.  Mention.  
    + The number of times others mention a user's name.
    + Represents the ability of the user to engage others in a conversation.
       
>__Why are FAVS or LIKES not included?__
>_Influence is measured by the spread of information from the source into the network. A tweet that the user liked is not shared to the user's followers; Also, the user's followers cannot know which tweets the user liked. Liking or Faving does not induce flow of information. A liked tweet is more likely to be retweeted anyway._ 
>__<SHOW CORELLATION AS PROOF>__

###Ranking

[Fractional rank](https://en.wikipedia.org/wiki/Ranking)

*  Rank of 1 is given to the most influential user and increasing rank indicates a less influential user. Users with the same influence score recieves the average of the rank amongst them.

***

### Deriving Indegree influence rank

Get data frame of unique users, disregard users with 0 followers:

```{r indeg dedupe nickname, echo=TRUE}

indegRanked <- stream %>% 
       filter(duplicated(Nickname) == FALSE) %>% 
       select(Nickname, Followers)

```

`r nrow(indegRanked)` out of `r length(unique(stream$Nickname))` unique users had followers > 0. `r length(unique(stream$Nickname)) - nrow(indegRanked)` users disregarded.

Adding fractional rank column to data frame.

```{r indeg frank, echo=TRUE}

IndegRank <- frank(indegRanked, -Followers, ties.method = 'average')
indegRanked$IndegRank <- IndegRank

saveRDS(indegRanked, file = "ca_indegRanked.RDS")

```

### Deriving Retweet influence rank

Get data frame of usernames and their total number of retweets.

NOTE: Total # of users with retweets > 0: 10462

```{r rt total per nickname}

##sum(RTs) returns sum of ALL tweets and not the sum of group_by
# RTtotalPerNick <-0
# retw_all <- stream %>% 
#        filter(`Is a RT` == FALSE & !is.na(RTs))  %>% 
#        filter(duplicated(`Tweet Id`) == FALSE)  %>% 
#        group_by(Nickname) %>% 
#        mutate(RTtotalPerNick = sum(RTs))

retw_all <- stream %>%
       filter(`Is a RT` == FALSE & RTs > 0)  %>%
       select(Nickname, RTs)

retwRanked <- aggregate(retw_all$RTs, by = list(retw_all$Nickname), FUN = sum)

names(retwRanked) <- c('Nickname', 'TotalRT')

```

Consolidating users with 0 RTs

```{r rt consolidate all nicknames}

retwRanked <- right_join(retwRanked, NicknameList, by = 'Nickname')
retwRanked <- retwRanked %>% mutate(TotalRT = ifelse(is.na(TotalRT),0,TotalRT))

```

Adding fractional rank column to data frame:

```{r rt frank}

retwRank <- frank(retwRanked, -TotalRT, ties.method = 'average')
retwRanked$retwRank <- retwRank

saveRDS(retwRanked, file = "ca_retwRanked.RDS")
###WHY IS THIS NOT WORKING???
#retwRanked <- u_RTtotal %>% 
#       mutate(retwRank = frank(-RTtotalPerNick, ties.method = 'average'))
```

## Deriving Mention influence rank

Get data frame of unique tweets with mentions. 

NOTE: Total # of users with mentions > 0: 18754

```{r mentions filter}

mentionRanked <- stream %>% 
       filter(`Is a RT` == FALSE & !is.na(`User Mentions`)) %>%
       select(`User Mentions`)

```

Convert data frame to vector to be able to split multiple mentions and remove @ symbol

```{r mentions to vector}

mentionRanked <- gsub('@','', as.vector(mentionRanked[['User Mentions']]))
mentionRanked <- unlist(strsplit(mentionRanked, ','))

```

Tabulate occurences and convert to data frame

```{r mentions tabulate}

mentionRanked <- as.data.frame(table(mentionRanked), stringsAsFactors = FALSE)
names(mentionRanked) <- c('Nickname', 'TotalMentions')

```

Consolidating users with 0 mentions

```{r mentions consolidate all nickname}

mentionRanked <- right_join(mentionRanked, NicknameList, by = 'Nickname')
mentionRanked <- mentionRanked %>% 
       mutate(TotalMentions = ifelse(is.na(TotalMentions),0,TotalMentions))

```

Adding fractional rank column to data frame:

```{r mentions frank}

menRank <- frank(mentionRanked, -TotalMentions, ties.method = 'average')
mentionRanked$menRank <- menRank


saveRDS(mentionRanked, file = "ca_mentionRanked.RDS")
```

***

## The Top Influentials

```{r top influentials}

indegTops <- as.data.frame(indegRanked) %>% 
       arrange(IndegRank) %>% select(Rank = IndegRank, TopIndegree = Nickname, RawFollowers = Followers) 
rtTops <- as.data.frame(retwRanked) %>% 
       arrange(retwRank) %>% select(Rank = retwRank, TopRT = Nickname, rawRTs = TotalRT)
menTops <- as.data.frame(mentionRanked) %>% 
       arrange(menRank) %>% select(Rank = menRank, TopMentions = Nickname, RawMentions = TotalMentions)

#Convert Rank column to Int
#Normalizing the list
class(indegTops$Rank) <- "integer"

rtTops$Rank <- 1:dim(retwRanked)[1]

menTops$Rank <- 1:dim(mentionRanked)[1]

#Join data frames
topInf <- left_join(left_join(indegTops,rtTops, by = 'Rank'), menTops, by = 'Rank')

write_csv(topInf, "caStreamTopsTable.csv")

kable(topInf[1:30, ], caption = 'Top 30 Influencers per Category')

```

```{r functions to find top inf}
### TRY TO VECTORIZE THIS LATER

findInt = function(topN){
       len <- 0
       inc <- 0
       while (len < topN){
              len <- length(intersect(intersect(indegTops[1:inc, 2], rtTops[1:inc, 2]),
                                      menTops[1:inc, 2]))
              inc <- inc +1
       }
       return(inc-1)
} 

findNames = function(int){
       intersect(intersect(indegTops[1:int, 2], rtTops[1:int, 2]), menTops[1:int, 2])
}

```


```{r functions to find top RTW and Mention}
### TRY TO VECTORIZE THIS LATER

findRTMen = function(topN){
       len <- 0
       inc <- 0
       while (len < topN){
              len <- length(intersect(menTops[1:inc, 2], rtTops[1:inc, 2]))
              inc <- inc +1
       }
       return(inc-1)
} 

findRTMenNames = function(int){
       intersect(menTops[1:int, 2], rtTops[1:int, 2])
}

```

Marginal overlaps were observed in these three top lists. These top `r findRTMen(1)` lists only had one user in common, `r findRTMenNames(findRTMen(1))`

***

The top 100 lists also showed marginal overlap.

```{r venn}

topVenn <- topInf[1:100, ]

xt <- list("Indegree" = topVenn$TopIndegree, "Retweet" = topVenn$TopRT, "Mentions" = topVenn$TopMentions)

venn.diagram(
       xt,
       height = 800,
       width = 800,
       euler.d = TRUE,
       scaled = TRUE,
       imagetype = "png",
       filename = "top100Venn.png",
       lty = "blank",
       cex = 0.25,
       cat.cex = 0.25,
       fill = c("skyblue", "pink1", "mediumorchid")
)

```
## Figure 1. Venn diagram of the top 100 influentials across measures.

![](top100Venn.png "Venn Diagram")

***

## Spearman's Correlation Coefficient

The correlation done on the top influential users show a stronger correlation in their retweet influence and mention influence.  
```{r spearman corr}

c.test <- right_join(right_join(indegRanked, mentionRanked, by = 'Nickname'), 
                     retwRanked, by = 'Nickname')

test.c <- c.test %>% arrange(IndegRank) %>% 
       select(IndegRank, menRank, retwRank) %>% top_n(-10000, wt = IndegRank)

spcor <- cor(test.c, method = 'spearman')

png(filename = "corrplot.png")

corrplot(
       spcor, 
       method = 'circle',
       outline = FALSE,
       type = 'upper',
       tl.col = "black"
       )
dev.off()
```

This means that in most cases, users who are retweeted often are also mentioned often, and vice versa.

***
