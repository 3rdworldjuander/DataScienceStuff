---
title: "NetworkGraph"
author: "Oamar Gianan"
date: "October 15, 2016"
output: html_document
---

## Network Graph

Creating the network object of the whole twitter stream involves creating a list of all the nodes and edges present between the nodes.

The edges are derived from the retweet and mention data. Links between the same users are aggregated and is listed as an edge attribute.

```{r edges, eval=FALSE, include=FALSE}
raw_edges <- stream %>%
        filter(!is.na(`Original Tweet User Name`) | !is.na(`User Mentions`))  %>%
        select(Nickname, RTs, `Is a RT`, `Original Tweet User Name`, `User Mentions`)

#write.csv(raw_edges, file = "raw_edges.csv")
#raw_edges <- read_csv("raw_edges.csv")      

#test <- raw_edges %>% filter(`Is a RT` == F)
men_edges <- raw_edges %>% filter(`Is a RT` == F)
rt_edges <- raw_edges %>% filter(`Is a RT` == T)

menMax <- max(str_count(men_edges$`User Mentions`, "@"))
men_edges <- men_edges %>% 
       separate(`User Mentions`, c(as.character(1:menMax)),
                ",", extra = "merge", fill = "left")

#gathering all users mentioned into one column
men_edges <- men_edges %>% gather(from_col, to, 5:15 )

#cleaning NAs and removing from_col
men_edges <- men_edges %>% filter(is.na(to) == FALSE) %>% select(from = Nickname, to)

#remove @ signs
men_edges$to <- gsub('@','', men_edges$to)


#fixing retweet df
rt_edges <- rt_edges %>% select(from = `Original Tweet User Name`, to =  Nickname)

#remove @ signs
rt_edges$from <- gsub('@','', rt_edges$from)

new_edges <- rbind(men_edges, rt_edges)

#aggregating to column
new_edges <- aggregate(rep(1, nrow(new_edges)), by = list(from = new_edges$from, to = new_edges$to), sum)

new_edges <- new_edges[order(new_edges$from, new_edges$to),]

colnames(new_edges)[3] <- "weight"
rownames(new_edges) <- NULL


links <- new_edges
```

The nodes are simply the list of all Nicknames. The number of followers of each Nickname is a weight attribute of the node.

```{r nodes, eval=FALSE}

nodes <- indegRanked

```

Creating the network object needs the igraph library.

```{r network graph, eval=FALSE, include=FALSE}

#drop to links not on nodes list 
dropNodes <- setdiff(links$to, nodes$Nickname)
links <-links[!(links$to %in% dropNodes),]

dropNodes <- setdiff(links$from, nodes$Nickname)
links <-links[!(links$from %in% dropNodes),]


library(igraph)

#build network object
twnet <- graph_from_data_frame(d=links, vertices=nodes, directed=T) 

head(V(twnet))
head(E(twnet))
head(degree(twnet))

twnet

```

## Network attributes

A closer look at the resulting network shows the following attributes.

```{r igraph attibutes, eval=FALSE, include=FALSE}

#The edges 
E(twnet)

#The vertices
V(twnet)

#Edge attributes
edge_attr(twnet)

#Vertices attributes
vertex_attr(twnet)

```

Network is too big, but I'll save it for later use.

```{r save igraph object, eval=FALSE, include=FALSE}

saveRDS(twnet, file = "twnet.RDS")

```

```{r read igraph object, eval=FALSE, include=FALSE}

twnet <- readRDS("twnet.RDS")

```


***

## Creating a smaller network

To create a smaller network, the twitter stream of a single company is read and loaded.

```{r read company csv, eval=FALSE, include=FALSE}

compStream <- read_csv("csv/export_dashboard_pypl_2016_06_15_13_51_08.csv")

#Discard duplicate tweets

compStream <- compStream %>% filter(duplicated(`Tweet Id`) == FALSE) 

#Adding timestamp
compStream$Timestamp <- as.POSIXct((compStream$Date +               seconds_to_period(compStream$Hour)), tz = "America/New_York")

```

```{r load company stream, include=FALSE}
###START HERE
#saveRDS(compStream, file = "filename.RDS")
library(igraph)
library(stringr)
library(tidyr)
library(dplyr)

compStream <- readRDS("caStream")

```

The nodes and edges are again derived from the stream data.

```{r company node, echo=TRUE}

compNode <- compStream %>% 
       filter(duplicated(Nickname) == FALSE) %>% 
       select(Nickname, Followers)

```

```{r company links}

raw_edges <- compStream %>%
        filter(!is.na(`Original Tweet User Name`) | !is.na(`User Mentions`))  %>%
        select(Nickname, RTs, `Is a RT`, `Original Tweet User Name`, `User Mentions`)

#write.csv(raw_edges, file = "raw_edges.csv")
#raw_edges <- read_csv("raw_edges.csv")      

#test <- raw_edges %>% filter(`Is a RT` == F)
men_edges <- raw_edges %>% filter(`Is a RT` == F)
rt_edges <- raw_edges %>% filter(`Is a RT` == T)

menMax <- max(str_count(men_edges$`User Mentions`, "@"))
men_edges <- men_edges %>% 
       separate(`User Mentions`, c(as.character(1:menMax)),
                ",", extra = "merge", fill = "left")

#gathering all users mentioned into one column
men_edges <- men_edges %>% gather(from_col, to, 5:15 )

#cleaning NAs and removing from_col
men_edges <- men_edges %>% filter(is.na(to) == FALSE) %>% select(from = Nickname, to)

#remove @ signs
men_edges$to <- gsub('@','', men_edges$to)


#fixing retweet df
rt_edges <- rt_edges %>% select(from = `Original Tweet User Name`, to =  Nickname)

#remove @ signs
rt_edges$from <- gsub('@','', rt_edges$from)

new_edges <- rbind(men_edges, rt_edges)

#aggregating to column
new_edges <- aggregate(rep(1, nrow(new_edges)), by = list(from = new_edges$from, to = new_edges$to), sum)

new_edges <- new_edges[order(new_edges$from, new_edges$to),]

colnames(new_edges)[3] <- "weight"
rownames(new_edges) <- NULL

compEdges <- new_edges
```

Creating the network object.

```{r smallNet}

#drop to links not on nodes list 
dropNodes <- setdiff(compEdges$to, compNode$Nickname)
compEdges <-compEdges[!(compEdges$to %in% dropNodes),]

dropNodes <- setdiff(compEdges$from, compNode$Nickname)
compEdges <-compEdges[!(compEdges$from %in% dropNodes),]


library(igraph)

#build network object
compNet <- graph_from_data_frame(d=compEdges, vertices=compNode, directed=T) 


compNet <- simplify(compNet, edge.attr.comb=list(weight="sum","ignore"))


```

```{r save network}
#saveRDS(compNet, file = "hsiccompNet.RDS")
```

Reviewing the smaller network

```{r comp igraph attibutes}

#The edges 
head(E(compNet))

#The vertices
head(V(compNet))

```

##Network Analysis

### Density
The proportion of present edges from all possible edges in the network.
```{r density}

edge_density(compNet, loops=F)
#CA [1] 0.005309448
#or

ecount(compNet)/(vcount(compNet)*(vcount(compNet)-1)) #for a directed network

```

### Reciprocity
The proportion of reciprocated ties (for a directed network).
```{r reciprocity}

reciprocity(compNet)

```


### Diameter
The diameter of a graph is the length of the longest geodesic.

```{r diameter}
diameter(compNet, directed=F, weights=NA)
#CA 9
get_diameter(compNet, directed=F, weights=NA)
#CA [1] belle_aura   gouluk1      ATPFtrading  ppprophet    StakepoolCom
# [6] CBOE         pnoytrader   ikesenmarble UTradePH     moredan20 

```

```{r coloring the diameter path, include=FALSE}

diam <- get_diameter(compNet, directed=F, weights=NA)

vcol <- rep("gray40", vcount(compNet))

vcol[diam] <- "gold"

ecol <- rep("gray80", ecount(compNet))

```

```{r plotting the graph}
png(filename = "network_diam.png", width = 2000, height = 2000, units = "px")
plot(compNet, 
     vertex.color=vcol, 
     edge.color=ecol,
     main = "Network Graph Showing Diameter",
#            layout=layout.fruchterman.reingold,
            edge.arrow.size=1, 
            edge.curved=0,
            vertex.frame.color="#555555",
            vertex.size=2, 
            vertex.label.color="black",
            vertex.label.cex = .7
     )
dev.off()

```

### Degree distribution

```{r degree dist, eval=FALSE, include=FALSE}

deg <- degree(compNet, mode="all")

hist(deg, breaks=1:vcount(compNet)-1, main="Histogram of node degree")

deg.dist <- degree_distribution(compNet, cumulative=T, mode="all")

plot( x=0:max(deg), y=1-deg.dist, pch=19, cex=1.2, col="orange", 

      xlab="Degree", ylab="Cumulative Frequency")

```


### Hubs and authorities
The hubs and authorities algorithm developed by Jon Kleinberg was initially used to examine web pages. Hubs were expected to contain catalogs with a large number of outgoing links; while authorities would get many incoming links from hubs, presumably because of their high-quality relevant information.

```{r HandA}
hs <- hub_score(compNet, scale = T)$vector
V(compNet)$hs <- hs
V(compNet)$as <- as

V(compNet)$hsas <- hs+as


hscomp <- hub_score(compNet, scale = T)
ascomp <- authority_score(compNet, scale = T)

as <- authority_score(compNet, scale = T)$vector

par(mfrow=c(1,2))

png(filename = "network_hsas.png", width = 2000, height = 2000, units = "px")
 plot(compNet, 
      vertex.size=V(compNet)$hsas * 5, 
      main="Hubs",
#            layout=layout.fruchterman.reingold,
            edge.arrow.size=0.5, 
            edge.curved=0,
            vertex.frame.color="#555555",
            vertex.size=2, 
            vertex.label.color="black",
            vertex.label.cex = .7
      )#, vertex.label = NA)
dev.off()

png(filename = "network_auth.png", width = 2000, height = 2000, units = "px") 
 plot(compNet, 
      vertex.size=as*10, 
      main="Authorities",
#            layout=layout.fruchterman.reingold,
            edge.arrow.size=0.5, 
            edge.curved=0,
            vertex.frame.color="#555555",
            vertex.size=2, 
            vertex.label.color="black",
            vertex.label.cex = .7
      )
 dev.off()


```

<!-- ## Eliminating Edges and Nodes -->

<!-- ```{r} -->
<!-- #removing weak edges -->

<!-- cut.off <- mean(compEdges$weight)  -->

<!-- compNet.se <- delete_edges(compNet, E(compNet)[weight<cut.off]) -->

<!-- png(filename = "lessEdge_network.png", width = 2000, height = 2000, units = "px") -->
<!-- plot(compNet.se,  -->
<!--             layout=layout.fruchterman.reingold, -->
<!--             edge.arrow.size=0.5,  -->
<!--             edge.curved=0, -->
<!--             vertex.frame.color="#555555", -->
<!--             vertex.size=2,  -->
<!--             vertex.label.color="black", -->
<!--             vertex.label.cex = .7 -->
<!--      )  -->
<!-- dev.off() -->

<!-- #exclude people who are in the network only tangentially (participate in one or two relationships only) -->

<!-- low.off<-V(compNet.se)[degree(compNet.se)<1]  -->
<!-- compNet.sen<-delete.vertices(compNet.se, low.off) #exclude them from the graph -->

<!-- # Plot the data.Some details about the graph can be specified in advance. -->
<!-- # For example we can separate some vertices (people) by color: -->
<!-- png(filename = "lessEdgeNodes_network.png", width = 2000, height = 2000, units = "px") -->
<!-- plot(compNet.sen, -->
<!--      main='Sparsified Network', -->
<!--             layout=layout.fruchterman.reingold, -->
<!--             edge.arrow.size=0.5,  -->
<!--             edge.curved=0, -->
<!--             vertex.frame.color="#555555", -->
<!--             vertex.size=2,  -->
<!--             vertex.label.color="black", -->
<!--             vertex.label.cex = .7 -->
<!-- ) -->
<!-- dev.off() -->

<!-- ``` -->